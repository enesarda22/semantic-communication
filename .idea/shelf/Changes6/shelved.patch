Index: train_relay_channel_block.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_relay_channel_block.py b/train_relay_channel_block.py
new file mode 100644
--- /dev/null	(date 1700970607603)
+++ b/train_relay_channel_block.py	(date 1700970607603)
@@ -0,0 +1,127 @@
+import argparse
+import os
+
+import numpy as np
+from tqdm import tqdm
+import torch
+
+from semantic_communication.data_processing.data_handler import DataHandler
+from semantic_communication.models.semantic_decoder import SemanticDecoder
+from semantic_communication.models.semantic_encoder import SemanticEncoder
+from semantic_communication.utils.general import (
+    get_device,
+    print_loss,
+    create_checkpoint,
+    set_seed,
+    add_semantic_decoder_args,
+    add_data_args,
+    add_train_args,
+    add_channel_model_args,
+)
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument("--relay-decoder-path", default=None, type=str)
+    add_semantic_decoder_args(parser)
+    add_data_args(parser)
+    add_train_args(parser)
+    add_channel_model_args(parser)
+    args = parser.parse_args()
+
+    set_seed()
+    device = get_device()
+
+    semantic_encoder = SemanticEncoder(max_length=args.max_length)
+    data_handler = DataHandler(
+        semantic_encoder=semantic_encoder,
+        batch_size=args.batch_size,
+        data_fp=args.data_fp,
+    )
+
+    relay_decoder = SemanticDecoder(
+        vocab_size=data_handler.vocab_size,
+        n_blocks=args.n_blocks,
+        n_heads=args.n_heads,
+        n_embeddings=args.n_embeddings,
+        block_size=args.max_length,
+    ).to(device)
+    optimizer = torch.optim.AdamW(relay_decoder.parameters(), lr=args.lr)
+
+    if args.relay_decoder_path is not None:
+        checkpoint = torch.load(args.relay_decoder_path)
+        relay_decoder.load_state_dict(checkpoint["model_state_dict"])
+        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
+
+    best_loss = torch.inf
+    for epoch in range(args.n_epochs):
+        train_losses = []
+        relay_decoder.train()
+        for b in tqdm(data_handler.train_dataloader):
+            xb = b[0].to(device)
+            attention_mask = b[1].to(device)
+
+            encoder_output = semantic_encoder(
+                input_ids=xb,
+                attention_mask=attention_mask,
+            )
+
+            xb = data_handler.encode_token_ids(xb)
+            logits, loss = relay_decoder(
+                encoder_output=encoder_output[:, :-1, :],
+                attention_mask=attention_mask[:, :-1],
+                targets=xb[:, 1:],
+            )
+
+            optimizer.zero_grad(set_to_none=True)
+            loss.backward()
+            optimizer.step()
+
+            train_losses.append(loss.item())
+
+        val_losses = []
+        relay_decoder.eval()
+        for b in data_handler.val_dataloader:
+            xb = b[0].to(device)
+            attention_mask = b[1].to(device)
+
+            encoder_output = semantic_encoder(
+                input_ids=xb,
+                attention_mask=attention_mask,
+            )
+            xb = data_handler.encode_token_ids(xb)
+
+            with torch.no_grad():
+                _, loss = relay_decoder(
+                    encoder_output=encoder_output[:, :-1, :],
+                    attention_mask=attention_mask[:, :-1],
+                    targets=xb[:, 1:],
+                )
+            val_losses.append(loss.item())
+
+        print("\n")
+        print_loss(train_losses, "Train")
+        print_loss(val_losses, "Val")
+
+        mean_loss = np.mean(val_losses)
+
+        checkpoint_path = os.path.join(
+            args.checkpoint_path,
+            f"relay-decoder/relay_decoder_{epoch}.pt",
+        )
+
+        if mean_loss < best_loss:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=relay_decoder.state_dict(),
+                optimizer_state_dict=optimizer.state_dict(),
+                mean_val_loss=mean_loss,
+            )
+            best_loss = mean_loss
+        else:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=None,
+                optimizer_state_dict=None,
+                mean_val_loss=mean_loss,
+            )
Index: semantic_communication/models/transceiver.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import numpy as np\nimport torch\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch import nn\n\nfrom semantic_communication.models.semantic_decoder import SemanticDecoder\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.utils.channel import Channel\nfrom semantic_communication.utils.general import get_device\n\n\nclass ChannelEncComp(nn.Module):\n    def __init__(self, in_dim, out_dim):\n        super(ChannelEncComp, self).__init__()\n        self.linear = nn.Linear(in_dim, out_dim)\n        self.bn = nn.BatchNorm1d(out_dim)\n        self.prelu = nn.PReLU()\n\n    def forward(self, x):\n        x = self.linear(x).transpose(1, 2)\n        x = self.bn(x).transpose(1, 2)\n        out = self.prelu(x)\n        return out\n\n\nclass ChannelEncoder(nn.Module):\n    def __init__(self, nin, nout):\n        super(ChannelEncoder, self).__init__()\n        up_dim = int(np.floor(np.log2(nin) / 2))\n        low_dim = int(np.ceil(np.log2(nout) / 2))\n\n        dims = [nin]\n        for i in range(up_dim - low_dim + 1):\n            dims.append(np.power(4, up_dim - i))\n\n        self.layers = nn.ModuleList(\n            [ChannelEncComp(dims[i], dims[i + 1]) for i in range(len(dims) - 1)]\n        )\n\n        self.linear = nn.Linear(dims[-1], nout)\n\n    def forward(self, x):\n        for l in self.layers:\n            x = l(x)\n        return self.linear(x)\n\n\nclass ChannelDecoder(nn.Module):\n    def __init__(self, nin, nout):\n        super(ChannelDecoder, self).__init__()\n        up_dim = int(np.floor(np.log2(nout) / 2))\n        low_dim = int(np.ceil(np.log2(nin) / 2))\n        dims = [nin]\n        for i in range(up_dim - low_dim + 1):\n            dims.append(np.power(4, low_dim + i))\n\n        self.layers = nn.ModuleList(\n            [ChannelEncComp(dims[i], dims[i + 1]) for i in range(len(dims) - 1)]\n        )\n\n        self.linear = nn.Linear(dims[-1], nout)\n\n    def forward(self, x):\n        x = x / torch.norm(x, dim=2, keepdim=True)\n        for l in self.layers:\n            x = l(x)\n        return self.linear(x)\n\n\nclass TxRelayChannelModel(nn.Module):\n    def __init__(self, nin, n_latent, channel: Channel):\n        super(TxRelayChannelModel, self).__init__()\n\n        self.tx_encoder = ChannelEncoder(nin, n_latent)\n        self.relay_decoder = ChannelDecoder(n_latent, nin)\n        self.channel = channel\n\n    def forward(self, x, d_sr):\n        ch_input = self.tx_encoder(x)\n        ch_output = self.channel(ch_input, d_sr)\n        x_hat = self.relay_decoder(ch_output)\n        return x_hat, ch_input\n\n\nclass TxRelayRxChannelModel(nn.Module):\n    def __init__(\n        self,\n        nin,\n        n_latent,\n        channel: Channel,\n    ):\n        super(TxRelayRxChannelModel, self).__init__()\n\n        self.relay_encoder = ChannelEncoder(nin, n_latent)\n        self.relay_rx_decoder = ChannelDecoder(n_latent, nin)\n        self.tx_rx_decoder = ChannelDecoder(n_latent, nin)\n        self.channel = channel\n\n    def forward(self, tx_ch_input, rel_x, d_rd, d_sd):\n        tx_ch_out = self.channel(tx_ch_input, d_sd)\n\n        rel_ch_input = self.relay_encoder(rel_x)\n        rel_ch_out = self.channel(rel_ch_input, d_rd)\n\n        x_hat = torch.cat(\n            [self.relay_rx_decoder(rel_ch_out), self.tx_rx_decoder(tx_ch_out)], dim=-1\n        )\n        return x_hat\n\n\nclass Transceiver(nn.Module):  # TODO: find a cooler name\n    def __init__(\n        self,\n        semantic_encoder: SemanticEncoder,\n        relay_semantic_decoder: SemanticDecoder,\n        rx_semantic_decoder: SemanticDecoder,\n        tx_relay_channel_enc_dec: TxRelayChannelModel,\n        tx_relay_rx_channel_enc_dec: TxRelayRxChannelModel,\n        encoder: LabelEncoder,\n    ):\n        super().__init__()\n        self.tx_semantic_encoder = semantic_encoder\n        self.relay = Relay(semantic_encoder, relay_semantic_decoder, encoder)\n        self.rx_semantic_decoder = rx_semantic_decoder\n\n        self.tx_relay_channel_enc_dec = tx_relay_channel_enc_dec\n        self.tx_relay_rx_channel_enc_dec = tx_relay_rx_channel_enc_dec\n\n    def forward(self, w, attention_mask, targets, d_sd, d_sr, d_rd):\n        # transmitter\n        encoder_output = self.tx_semantic_encoder(\n            input_ids=w,\n            attention_mask=attention_mask,\n        )\n\n        # relay\n        relay_input, tx_ch_input = self.tx_relay_channel_enc_dec(\n            encoder_output[:, :-1, :], d_sr\n        )\n        relay_output = self.relay(relay_input)\n\n        # receiver\n        receiver_input = self.tx_relay_rx_channel_enc_dec(\n            tx_ch_input, relay_output, d_rd, d_sd\n        )\n        receiver_output = self.rx_semantic_decoder(\n            encoder_output=receiver_input,\n            attention_mask=attention_mask[:, 1:],\n            targets=targets,\n        )\n        return receiver_output\n\n\nclass Relay(nn.Module):\n    def __init__(\n        self,\n        semantic_encoder: SemanticEncoder,\n        semantic_decoder: SemanticDecoder,\n        encoder: LabelEncoder,\n    ):\n        super().__init__()\n        self.device = get_device()\n        self.semantic_encoder = semantic_encoder\n        self.semantic_decoder = semantic_decoder\n        self.encoder = encoder\n\n    def forward(self, x):\n        B, T, C = x.shape\n\n        self.semantic_decoder.eval()\n        with torch.no_grad():\n            predicted_ids = self.semantic_decoder.generate(x)\n\n        predicted_ids = self.encoder.inverse_transform(\n            predicted_ids.flatten().to(\"cpu\")\n        ).reshape(B, T)\n        predicted_ids = torch.LongTensor(predicted_ids).to(self.device)\n\n        # ids are repeated to generate the embeddings sequentially\n        predicted_ids = torch.repeat_interleave(predicted_ids, T, dim=0)\n\n        # append [CLS] token\n        cls_padding = torch.full((B * T, 1), 101).to(self.device)\n        predicted_ids = torch.cat(\n            tensors=(cls_padding, predicted_ids),\n            dim=1,\n        )\n\n        # tril mask to generate the embeddings sequentially\n        tril_mask = (\n            torch.tril(\n                torch.ones(T, T + 1, dtype=torch.long),\n                diagonal=1,\n            ).repeat(B, 1)\n        ).to(self.device)\n\n        out = self.semantic_encoder(\n            input_ids=predicted_ids,\n            attention_mask=tril_mask,\n        )\n\n        # use eye mask to select the correct embeddings sequentially\n        eye_mask = (torch.eye(T).repeat(1, B) == 1).to(self.device)\n        out = torch.masked_select(out[:, 1:, :].transpose(-1, 0), eye_mask)\n        out = out.view(B, T, C)\n\n        return out\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/semantic_communication/models/transceiver.py b/semantic_communication/models/transceiver.py
--- a/semantic_communication/models/transceiver.py	(revision c77927ca0346ba4d7a4a1ef00f7ec1a1ef8ea242)
+++ b/semantic_communication/models/transceiver.py	(date 1700970836281)
@@ -151,6 +151,22 @@
         return receiver_output
 
 
+class RelayChannelBlock(nn.Module):
+    def __init__(
+        self,
+        semantic_decoder: SemanticDecoder,
+        tx_relay_channel_enc_dec: TxRelayChannelModel,
+    ):
+        super().__init__()
+        self.semantic_decoder = semantic_decoder
+        self.tx_relay_channel_enc_dec = tx_relay_channel_enc_dec
+
+    def forward(self, x):
+        self.semantic_decoder.eval()
+        with torch.no_grad():
+            predicted_ids = self.semantic_decoder.generate(x)
+
+
 class Relay(nn.Module):
     def __init__(
         self,
