Index: train_src_relay_block.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\n\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\n\nfrom semantic_communication.data_processing.data_handler import DataHandler\nfrom semantic_communication.models.semantic_decoder import SemanticDecoder\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.models.semantic_transformer import SemanticTransformer\nfrom semantic_communication.models.transceiver import ChannelEncoder, ChannelDecoder, SrcRelayBlock\n\nfrom semantic_communication.utils.channel import init_channel, get_distance\nfrom semantic_communication.utils.general import (\n    get_device,\n    print_loss,\n    create_checkpoint,\n    set_seed,\n    add_semantic_decoder_args,\n    add_data_args,\n    add_train_args,\n    add_channel_model_args,\n    load_model, load_optimizer, load_scheduler, get_start_epoch,\n)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"--semantic-transformer-path\", default=None, type=str)\n    parser.add_argument(\"--src-relay-block-path\", default=None, type=str)\n    add_semantic_decoder_args(parser)\n    add_data_args(parser)\n    add_train_args(parser)\n    add_channel_model_args(parser)\n    args = parser.parse_args()\n\n    set_seed()\n    device = get_device()\n\n    data_handler = DataHandler(\n        batch_size=args.batch_size,\n        data_fp=args.data_fp,\n    )\n\n    semantic_encoder = SemanticEncoder(\n        label_encoder=data_handler.label_encoder,\n        max_length=args.max_length,\n        mode=args.mode,\n        rate=args.rate,\n    ).to(device)\n\n    semantic_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n        bert=semantic_encoder.bert,\n        pad_idx=data_handler.label_encoder.pad_id,\n    ).to(device)\n\n    semantic_transformer = SemanticTransformer(\n        semantic_encoder=semantic_encoder,\n        semantic_decoder=semantic_decoder,\n    ).to(device)\n    load_model(semantic_transformer, args.semantic_transformer_path)\n\n    src_channel_encoder = ChannelEncoder(\n        nin=args.channel_block_input_dim,\n        nout=args.channel_block_latent_dim,\n    ).to(device)\n\n    relay_channel_decoder = ChannelDecoder(\n        nin=args.channel_block_latent_dim,\n        nout=args.channel_block_input_dim,\n    ).to(device)\n\n    channel = init_channel(args.channel_type, args.sig_pow, args.alpha, args.noise_pow)\n\n    src_relay_block = SrcRelayBlock(\n        semantic_transformer=semantic_transformer,\n        src_channel_encoder=src_channel_encoder,\n        relay_channel_decoder=relay_channel_decoder,\n        channel=channel,\n    ).to(device)\n    load_model(src_relay_block, args.src_relay_block_path)\n\n    optimizer = torch.optim.AdamW(src_relay_block.parameters(), lr=args.lr)\n    if args.load_optimizer:\n        load_optimizer(optimizer, args.src_relay_block_path)\n\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=args.lr,\n        steps_per_epoch=len(data_handler.train_dataloader),\n        epochs=args.n_epochs,\n    )\n    if args.load_scheduler:\n        load_scheduler(scheduler, args.src_relay_block_path)\n\n    start_epoch = get_start_epoch(args.src_relay_block_path)\n    best_loss = torch.inf\n    for epoch in range(start_epoch, args.n_epochs + 1):\n        train_losses = []\n        src_relay_block.train()\n        for b in tqdm(data_handler.train_dataloader):\n            encoder_idx = b[0].to(device)\n            encoder_attention_mask = b[1].to(device)\n\n            encoder_idx = data_handler.label_encoder.transform(encoder_idx)\n\n            d_sd = get_distance(args.d_min, args.d_max)\n            d_sr = get_distance(d_sd * args.gamma_min, d_sd * args.gamma_max)\n\n            _, loss = src_relay_block(\n                input_ids=encoder_idx,\n                attention_mask=encoder_attention_mask,\n                d_sr=d_sr,\n            )\n\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n\n            train_losses.append(loss.item())\n\n        val_losses = []\n        src_relay_block.eval()\n        for b in data_handler.val_dataloader:\n            encoder_idx = b[0].to(device)\n            encoder_attention_mask = b[1].to(device)\n\n            encoder_idx = data_handler.label_encoder.transform(encoder_idx)\n\n            d_sd = get_distance(args.d_min, args.d_max)\n            d_sr = get_distance(d_sd * args.gamma_min, d_sd * args.gamma_max)\n\n            with torch.no_grad():\n                _, loss = src_relay_block(\n                    input_ids=encoder_idx,\n                    attention_mask=encoder_attention_mask,\n                    d_sr=d_sr,\n                )\n            val_losses.append(loss.item())\n\n        print(\"\\n\")\n        print_loss(train_losses, \"Train\")\n        print_loss(val_losses, \"Val\")\n\n        mean_loss = np.mean(val_losses)\n\n        checkpoint_path = os.path.join(\n            args.checkpoint_path,\n            f\"src-relay-block/src_relay_block_{epoch}.pt\",\n        )\n\n        if mean_loss < best_loss:\n            create_checkpoint(\n                path=checkpoint_path,\n                model_state_dict=src_relay_block.state_dict(),\n                optimizer_state_dict=optimizer.state_dict(),\n                mean_val_loss=mean_loss,\n            )\n            best_loss = mean_loss\n        else:\n            create_checkpoint(\n                path=checkpoint_path,\n                model_state_dict=None,\n                optimizer_state_dict=None,\n                mean_val_loss=mean_loss,\n            )\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_src_relay_block.py b/train_src_relay_block.py
--- a/train_src_relay_block.py	(revision cad0f871753e4e48d32315ebcb817d0c732a67c2)
+++ b/train_src_relay_block.py	(date 1714277019802)
@@ -9,7 +9,11 @@
 from semantic_communication.models.semantic_decoder import SemanticDecoder
 from semantic_communication.models.semantic_encoder import SemanticEncoder
 from semantic_communication.models.semantic_transformer import SemanticTransformer
-from semantic_communication.models.transceiver import ChannelEncoder, ChannelDecoder, SrcRelayBlock
+from semantic_communication.models.transceiver import (
+    ChannelEncoder,
+    ChannelDecoder,
+    SrcRelayBlock,
+)
 
 from semantic_communication.utils.channel import init_channel, get_distance
 from semantic_communication.utils.general import (
@@ -21,7 +25,10 @@
     add_data_args,
     add_train_args,
     add_channel_model_args,
-    load_model, load_optimizer, load_scheduler, get_start_epoch,
+    load_model,
+    load_optimizer,
+    load_scheduler,
+    get_start_epoch,
 )
 
 
@@ -162,7 +169,9 @@
                 path=checkpoint_path,
                 model_state_dict=src_relay_block.state_dict(),
                 optimizer_state_dict=optimizer.state_dict(),
+                scheduler_state_dict=scheduler.state_dict(),
                 mean_val_loss=mean_loss,
+                epoch=epoch,
             )
             best_loss = mean_loss
         else:
@@ -170,5 +179,7 @@
                 path=checkpoint_path,
                 model_state_dict=None,
                 optimizer_state_dict=None,
+                scheduler_state_dict=None,
                 mean_val_loss=mean_loss,
+                epoch=epoch,
             )
