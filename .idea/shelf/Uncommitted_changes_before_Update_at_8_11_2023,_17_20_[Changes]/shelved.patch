Index: Baseline/eval_baseline.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom utils.general import get_device, set_seed\nfrom baseline_models.tx_relay_rx_models import Tx_Relay, Tx_Relay_Rx\n\nfrom data_processing.data_handler import DataHandler\nfrom data_processing.semantic_encoder import SemanticEncoder\nfrom utils.channel import AWGN, Rayleigh\nimport torch\nimport argparse\nfrom torch.nn import functional as F\n\n\n\ndef semantic_similarity_score(target_sentences, received_sentences):\n    target_emb = semantic_encoder(messages=target_sentences)\n    received_emb = semantic_encoder(messages=received_sentences)\n    scores = F.cosine_similarity(target_emb, received_emb)\n\n    return scores\n\n\ndef bleu_1gram(target_sentences, received_sentences):\n    # score = []\n    # for (sent1, sent2) in zip(target_sentences, received_sentences):\n    #     sent1 = sent1.split()\n    #     sent2 = sent2.split()\n    #     score.append(sentence_bleu([sent1], sent2,\n    #                                weights=(1, 0, 0, 0)))\n    return sentence_bleu(\n        [target_sentences], received_sentences, weights=(1, 0, 0, 0)\n    )\n\n\ndef bleu_2gram(target_sentences, received_sentences):\n    # score = []\n    # for (sent1, sent2) in zip(target_sentences, received_sentences):\n    #     sent1 = sent1.split()\n    #     sent2 = sent2.split()\n    #     score.append(sentence_bleu([sent1], sent2,\n    #                                weights=(0, 1, 0, 0)))\n    return sentence_bleu(\n        [target_sentences], received_sentences, weights=(0, 1, 0, 0)\n    )\n\n\ndef bleu_3gram(target_sentences, received_sentences):\n    # score = []\n    # for (sent1, sent2) in zip(target_sentences, received_sentences):\n    #     sent1 = sent1.split()\n    #     sent2 = sent2.split()\n    #     score.append(sentence_bleu([sent1], sent2,\n    #                                weights=(0, 0, 1, 0)))\n    return sentence_bleu(\n        [target_sentences], received_sentences, weights=(0, 0, 1, 0)\n    )\n\n\ndef bleu_4gram(target_sentences, received_sentences):\n    # score = []\n    # for (sent1, sent2) in zip(target_sentences, received_sentences):\n    #     sent1 = sent1.split()\n    #     sent2 = sent2.split()\n    #     score.append(sentence_bleu([sent1], sent2,\n    #                                weights=(0, 0, 0, 1)))\n    return sentence_bleu(\n        [target_sentences], received_sentences, weights=(0, 0, 0, 1)\n    )\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--tx-relay-path\", type=str)\n    parser.add_argument(\"--tx-relay-rx-path\", type=str)\n\n    parser.add_argument(\"--SNR-list\", nargs=\"+\", type=int)\n\n    parser.add_argument(\"--checkpoint-path\", default=\"checkpoints\", type=str)\n    parser.add_argument(\"--n-samples\", default=10000, type=int)\n    parser.add_argument(\"--train-size\", default=0.9, type=float)\n    parser.add_argument(\"--max-length\", default=30, type=int)\n    parser.add_argument(\"--batch-size\", default=32, type=int)\n    parser.add_argument(\"--n-epochs\", default=10, type=int)\n    parser.add_argument(\"--lr\", default=1e-4, type=float)\n    parser.add_argument(\"--n-blocks\", default=1, type=int)\n    parser.add_argument(\"--n-heads\", default=4, type=int)\n    parser.add_argument(\"--n-embeddings\", default=384, type=int)\n\n    # New args\n    parser.add_argument(\"--channel-block-input-dim\", default=384, type=int)\n    parser.add_argument(\"--channel-block-latent-dim\", default=128, type=int)\n    parser.add_argument(\"--val-size\", default=0.2, type=float)\n    parser.add_argument(\"--sig-pow\", default=1.0, type=float)\n    parser.add_argument(\"--SNR-diff\", default=3, type=int)\n    parser.add_argument(\"--channel-type\", default=\"AWGN\", type=str)\n    args = parser.parse_args()\n\n    device = get_device()\n    set_seed()\n    # Create Data handler\n    semantic_encoder = SemanticEncoder(max_length=args.max_length)\n    data_handler = DataHandler(\n        semantic_encoder=semantic_encoder,\n        batch_size=args.batch_size,\n        n_samples=args.n_samples,\n        train_size=args.train_size,\n        val_size=args.val_size,\n    )\n    data_handler.load_data()\n\n    # Create Channels\n    if args.channel_type == \"AWGN\":\n        tx_rx_channel = AWGN(\n            int(args.SNR_list[0]) - args.SNR_diff, args.sig_pow\n        )\n        tx_relay_channel = AWGN(int(args.SNR_list[0]), args.sig_pow)\n        relay_rx_channel = AWGN(int(args.SNR_list[0]), args.sig_pow)\n\n    else:\n        tx_rx_channel = Rayleigh(\n            int(args.SNR_list[0]) - args.SNR_diff, args.sig_pow\n        )\n        tx_relay_channel = Rayleigh(int(args.SNR_list[0]), args.sig_pow)\n        relay_rx_channel = Rayleigh(int(args.SNR_list[0]), args.sig_pow)\n\n    num_classes = data_handler.vocab_size\n\n    # Create Transceiver\n    tx_relay_model = Tx_Relay(num_classes, n_emb=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel=tx_relay_channel).to(device)\n    tx_relay_checkpoint = torch.load(args.tx_relay_path)\n    tx_relay_model.load_state_dict(tx_relay_checkpoint[\"model_state_dict\"])\n\n    tx_relay_rx_model = Tx_Relay_Rx(num_classes, args.channel_block_input_dim, args.channel_block_latent_dim, tx_rx_channel, relay_rx_channel,tx_relay_model).to(device)\n    tx_relay_rx_checkpoint = torch.load(args.tx_relay_rx_path)\n    tx_relay_rx_model.load_state_dict(tx_relay_rx_checkpoint[\"model_state_dict\"])\n\n    semantic_sim = []\n    bleu_1 = []\n    bleu_2 = []\n    bleu_3 = []\n    bleu_4 = []\n    for SNR in args.SNR_list:\n        print(\"Simulating for SNR: \" + str(SNR))\n        # Create Channels\n        if args.channel_type == \"AWGN\":\n            tx_rx_channel = AWGN(int(SNR) - args.SNR_diff, args.sig_pow)\n            tx_relay_channel = AWGN(int(SNR), args.sig_pow)\n            relay_rx_channel = AWGN(int(SNR), args.sig_pow)\n\n        else:\n            tx_rx_channel = Rayleigh(int(SNR) - args.SNR_diff, args.sig_pow)\n            tx_relay_channel = Rayleigh(int(SNR), args.sig_pow)\n            relay_rx_channel = Rayleigh(int(SNR), args.sig_pow)\n\n        tx_relay_rx_model.tx_rx_channel = tx_rx_channel\n        tx_relay_rx_model.relay_rx_channel = relay_rx_channel\n        tx_relay_rx_model.tx_relay_model.channel = tx_relay_channel\n\n        cosine_scores = []\n        bleu1_scores = []\n        bleu2_scores = []\n        bleu3_scores = []\n        bleu4_scores = []\n\n        tx_relay_rx_model.eval()\n        for b in data_handler.test_dataloader:\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            B, T = xb.shape\n\n            with torch.no_grad():\n                logits, _ = tx_relay_rx_model(xb, attention_mask)\n                probs = F.softmax(logits, dim=-1)\n                predicted_ids = (torch.argmax(probs, dim=-1)).reshape(\n                    B, args.max_length\n                )\n\n                end_token_id = data_handler.encoder.transform([102])[0]\n                end_prediction_idx = torch.argmax(\n                    predicted_ids.eq(end_token_id).double(), dim=1\n                )\n\n                # zero means no end token prediction\n                end_prediction_idx[end_prediction_idx == 0] = T - 1\n\n                # prediction mask is created based on end token predictions\n                pred_mask = (torch.arange(T - 1).to(device)).le(\n                    end_prediction_idx.view(-1, 1)\n                )\n\n                predicted_sentences = data_handler.get_tokens(\n                    ids=predicted_ids,\n                    attention_mask=pred_mask,\n                    skip_special_tokens=True,\n                )\n\n                original_sentences = data_handler.get_tokens(\n                    ids=xb,\n                    attention_mask=attention_mask,\n                    skip_special_tokens=True,\n                )\n\n                for s1, s2 in zip(original_sentences, predicted_sentences):\n                    cosine_scores.append(\n                        semantic_similarity_score([s1], [s2])[0][0]\n                    )\n\n                    bleu1_scores.append(bleu_1gram(s1, s2))\n                    bleu2_scores.append(bleu_2gram(s1, s2))\n                    bleu3_scores.append(bleu_3gram(s1, s2))\n                    bleu4_scores.append(bleu_4gram(s1, s2))\n\n        semantic_sim.append(np.mean(cosine_scores))\n        bleu_1.append(np.mean(bleu1_scores))\n        bleu_2.append(np.mean(bleu2_scores))\n        bleu_3.append(np.mean(bleu3_scores))\n        bleu_4.append(np.mean(bleu4_scores))\n\n    snr_np = np.array(args.SNR_list).astype(int)\n\n    plt.figure()\n    plt.plot(args.SNR_list, semantic_sim)\n    plt.grid()\n    plt.xlabel(\"Channel SNR (dB)\")\n    plt.ylabel(\"Semantic Similarity\")\n    plt.xticks(np.arange(np.min(snr_np), np.max(snr_np), 3))\n    plt.title(\"Semantic Similarity v. Channel SNR (dB)\")\n    plt.savefig(\"SemanticSimilarty_v_SNR.png\", dpi=400)\n\n    plt.figure()\n    plt.plot(args.SNR_list, bleu_1)\n    plt.grid()\n    plt.xlabel(\"Channel SNR (dB)\")\n    plt.ylabel(\"BLEU 1-gram\")\n    plt.xticks(np.arange(np.min(snr_np), np.max(snr_np), 3))\n    plt.title(\"BLEU 1-gram v. Channel SNR (dB)\")\n    plt.savefig(\"BLEU1gram_v_SNR.png\", dpi=400)\n\n    plt.figure()\n    plt.plot(args.SNR_list, bleu_2)\n    plt.grid()\n    plt.xlabel(\"Channel SNR (dB)\")\n    plt.ylabel(\"BLEU 2-gram\")\n    plt.xticks(np.arange(np.min(snr_np), np.max(snr_np), 3))\n    plt.title(\"BLEU 2-gram v. Channel SNR (dB)\")\n    plt.savefig(\"BLEU2gam_v_SNR.png\", dpi=400)\n\n    plt.figure()\n    plt.plot(args.SNR_list, bleu_3)\n    plt.grid()\n    plt.xlabel(\"Channel SNR (dB)\")\n    plt.ylabel(\"BLEU 3-gram\")\n    plt.xticks(np.arange(np.min(snr_np), np.max(snr_np), 3))\n    plt.title(\"BLEU 3-gram v. Channel SNR (dB)\")\n    plt.savefig(\"BLEU3gram_v_SNR.png\", dpi=400)\n\n    plt.figure()\n    plt.plot(args.SNR_list, bleu_4)\n    plt.grid()\n    plt.xlabel(\"Channel SNR (dB)\")\n    plt.ylabel(\"BLEU 4-gram\")\n    plt.xticks(np.arange(np.min(snr_np), np.max(snr_np), 3))\n    plt.title(\"BLEU 4-gram v. Channel SNR (dB)\")\n    plt.savefig(\"BLEU4gram_v_SNR.png\", dpi=400)\n\n    with open('semantic_sim.npy', 'wb') as f:\n        np.save(f, semantic_sim)\n\n    with open('bleu_1.npy', 'wb') as f:\n        np.save(f, bleu_1)\n\n    with open('bleu_2.npy', 'wb') as f:\n        np.save(f, bleu_2)\n\n    with open('bleu_3.npy', 'wb') as f:\n        np.save(f, bleu_3)\n\n    with open('bleu_4.npy', 'wb') as f:\n        np.save(f, bleu_4)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Baseline/eval_baseline.py b/Baseline/eval_baseline.py
--- a/Baseline/eval_baseline.py	(revision 5566b652f3e3a951d41878db04a04636a72d5283)
+++ b/Baseline/eval_baseline.py	(date 1699378630580)
@@ -13,7 +13,6 @@
 from torch.nn import functional as F
 
 
-
 def semantic_similarity_score(target_sentences, received_sentences):
     target_emb = semantic_encoder(messages=target_sentences)
     received_emb = semantic_encoder(messages=received_sentences)
@@ -78,14 +77,9 @@
     parser.add_argument("--SNR-list", nargs="+", type=int)
 
     parser.add_argument("--checkpoint-path", default="checkpoints", type=str)
-    parser.add_argument("--n-samples", default=10000, type=int)
-    parser.add_argument("--train-size", default=0.9, type=float)
+    parser.add_argument("--data-fp", default="", type=str)
     parser.add_argument("--max-length", default=30, type=int)
     parser.add_argument("--batch-size", default=32, type=int)
-    parser.add_argument("--n-epochs", default=10, type=int)
-    parser.add_argument("--lr", default=1e-4, type=float)
-    parser.add_argument("--n-blocks", default=1, type=int)
-    parser.add_argument("--n-heads", default=4, type=int)
     parser.add_argument("--n-embeddings", default=384, type=int)
 
     # New args
@@ -104,11 +98,8 @@
     data_handler = DataHandler(
         semantic_encoder=semantic_encoder,
         batch_size=args.batch_size,
-        n_samples=args.n_samples,
-        train_size=args.train_size,
-        val_size=args.val_size,
+        data_fp=args.data_fp,
     )
-    data_handler.load_data()
 
     # Create Channels
     if args.channel_type == "AWGN":
@@ -128,13 +119,29 @@
     num_classes = data_handler.vocab_size
 
     # Create Transceiver
-    tx_relay_model = Tx_Relay(num_classes, n_emb=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel=tx_relay_channel).to(device)
-    tx_relay_checkpoint = torch.load(args.tx_relay_path)
+    tx_relay_model = Tx_Relay(
+        num_classes,
+        n_emb=args.channel_block_input_dim,
+        n_latent=args.channel_block_latent_dim,
+        channel=tx_relay_channel,
+    ).to(device)
+    tx_relay_checkpoint = torch.load(args.tx_relay_path, map_location=device)
     tx_relay_model.load_state_dict(tx_relay_checkpoint["model_state_dict"])
 
-    tx_relay_rx_model = Tx_Relay_Rx(num_classes, args.channel_block_input_dim, args.channel_block_latent_dim, tx_rx_channel, relay_rx_channel,tx_relay_model).to(device)
-    tx_relay_rx_checkpoint = torch.load(args.tx_relay_rx_path)
-    tx_relay_rx_model.load_state_dict(tx_relay_rx_checkpoint["model_state_dict"])
+    tx_relay_rx_model = Tx_Relay_Rx(
+        num_classes,
+        args.channel_block_input_dim,
+        args.channel_block_latent_dim,
+        tx_rx_channel,
+        relay_rx_channel,
+        tx_relay_model,
+    ).to(device)
+    tx_relay_rx_checkpoint = torch.load(
+        args.tx_relay_rx_path, map_location=device
+    )
+    tx_relay_rx_model.load_state_dict(
+        tx_relay_rx_checkpoint["model_state_dict"]
+    )
 
     semantic_sim = []
     bleu_1 = []
@@ -266,17 +273,17 @@
     plt.title("BLEU 4-gram v. Channel SNR (dB)")
     plt.savefig("BLEU4gram_v_SNR.png", dpi=400)
 
-    with open('semantic_sim.npy', 'wb') as f:
+    with open("semantic_sim.npy", "wb") as f:
         np.save(f, semantic_sim)
 
-    with open('bleu_1.npy', 'wb') as f:
+    with open("bleu_1.npy", "wb") as f:
         np.save(f, bleu_1)
 
-    with open('bleu_2.npy', 'wb') as f:
+    with open("bleu_2.npy", "wb") as f:
         np.save(f, bleu_2)
 
-    with open('bleu_3.npy', 'wb') as f:
+    with open("bleu_3.npy", "wb") as f:
         np.save(f, bleu_3)
 
-    with open('bleu_4.npy', 'wb') as f:
+    with open("bleu_4.npy", "wb") as f:
         np.save(f, bleu_4)
