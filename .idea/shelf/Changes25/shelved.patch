Index: train_end_to_end.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\n\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom tqdm import tqdm\n\nfrom semantic_communication.data_processing.data_handler import DataHandler\nfrom semantic_communication.models.semantic_transformer import SemanticTransformer\nfrom semantic_communication.models.transceiver import (\n    Transceiver,\n    ChannelEncoder,\n    ChannelDecoder,\n    init_dst_channel_decoder,\n)\nfrom semantic_communication.utils.channel import (\n    init_channel,\n    get_distance,\n)\nfrom semantic_communication.models.semantic_decoder import SemanticDecoder\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.utils.general import (\n    get_device,\n    print_loss,\n    create_checkpoint,\n    set_seed,\n    add_semantic_decoder_args,\n    add_channel_model_args,\n    add_data_args,\n    add_train_args,\n    load_model,\n    load_optimizer,\n    load_scheduler,\n    get_start_epoch,\n)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--transceiver-path\", type=str)\n    parser.add_argument(\"--semantic-transformer-path\", default=None, type=str)\n    add_semantic_decoder_args(parser)\n    add_data_args(parser)\n    add_train_args(parser)\n    add_channel_model_args(parser)\n    args = parser.parse_args()\n\n    set_seed()\n    device = get_device()\n\n    print(torch.cuda.device_count())\n\n    data_handler = DataHandler(\n        batch_size=args.batch_size,\n        data_fp=args.data_fp,\n    )\n\n    semantic_encoder = SemanticEncoder(\n        label_encoder=data_handler.label_encoder,\n        max_length=args.max_length,\n        mode=args.mode,\n        rate=args.rate,\n    ).to(device)\n\n    semantic_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n        bert=semantic_encoder.bert,\n        pad_idx=data_handler.label_encoder.pad_id,\n    ).to(device)\n\n    channel_encoder = ChannelEncoder(\n        nin=args.channel_block_input_dim,\n        nout=args.channel_block_latent_dim,\n    ).to(device)\n\n    channel_decoder = ChannelDecoder(\n        nin=args.channel_block_latent_dim,\n        nout=args.channel_block_input_dim,\n    ).to(device)\n\n    channel = init_channel(args.channel_type, args.sig_pow, args.alpha, args.noise_pow)\n\n    semantic_transformer = SemanticTransformer(\n        semantic_encoder=semantic_encoder,\n        semantic_decoder=semantic_decoder,\n        channel_encoder=channel_encoder,\n        channel_decoder=channel_decoder,\n        channel=channel,\n    ).to(device)\n    load_model(semantic_transformer, args.semantic_transformer_path)\n\n    relay_semantic_encoder = SemanticEncoder(\n        label_encoder=data_handler.label_encoder,\n        max_length=args.max_length,\n        mode=args.mode if args.mode == \"sentence\" else \"forward\",\n        rate=args.rate,\n    ).to(device)\n    relay_semantic_encoder.load_state_dict(\n        semantic_transformer.semantic_encoder.state_dict()\n    )\n\n    relay_channel_encoder = ChannelEncoder(\n        nin=args.channel_block_input_dim,\n        nout=args.channel_block_latent_dim,\n    ).to(device)\n    relay_channel_encoder.load_state_dict(\n        semantic_transformer.channel_encoder.state_dict()\n    )\n\n    dst_channel_decoder = ChannelDecoder(\n        nin=args.channel_block_latent_dim * 2,\n        nout=args.channel_block_input_dim,\n    ).to(device)\n    state_dict = init_dst_channel_decoder(semantic_transformer)\n    dst_channel_decoder.load_state_dict(state_dict, strict=False)\n\n    dst_semantic_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n        bert=relay_semantic_encoder.bert,\n        pad_idx=data_handler.label_encoder.pad_id,\n    ).to(device)\n    dst_semantic_decoder.load_state_dict(\n        semantic_transformer.semantic_decoder.state_dict()\n    )\n\n    transceiver = Transceiver(\n        src_relay_transformer=semantic_transformer,\n        relay_semantic_encoder=relay_semantic_encoder,\n        relay_channel_encoder=relay_channel_encoder,\n        dst_channel_decoder=dst_channel_decoder,\n        dst_semantic_decoder=dst_semantic_decoder,\n        channel=channel,\n        max_length=args.max_length,\n    )\n    transceiver = nn.DataParallel(transceiver)\n    transceiver = transceiver.to(device)\n    load_model(transceiver, args.transceiver_path)\n\n    optimizer = torch.optim.AdamW(transceiver.parameters(), lr=args.lr)\n    if args.load_optimizer:\n        load_optimizer(optimizer, args.transceiver_path)\n\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=args.lr,\n        steps_per_epoch=len(data_handler.train_dataloader),\n        epochs=args.n_epochs,\n    )\n    if args.load_scheduler:\n        load_scheduler(scheduler, args.transceiver_path)\n        start_epoch = get_start_epoch(args.transceiver_path)\n    else:\n        start_epoch = 1\n\n    best_loss = torch.inf\n    for epoch in range(start_epoch, args.n_epochs + 1):\n        train_losses = []\n        transceiver.train()\n\n        for b in tqdm(data_handler.train_dataloader):\n            encoder_idx = b[0].to(device)\n            encoder_attention_mask = b[1].to(device)\n\n            encoder_idx = data_handler.label_encoder.transform(encoder_idx)\n\n            d_sd = get_distance(args.d_min, args.d_max)\n            d_sr = get_distance(d_sd * args.gamma_min, d_sd * args.gamma_max)\n\n            _, loss = transceiver(\n                input_ids=encoder_idx,\n                attention_mask=encoder_attention_mask,\n                d_sd=d_sd,\n                d_sr=d_sr,\n            )\n\n            optimizer.zero_grad(set_to_none=True)\n            loss.mean().backward()\n            optimizer.step()\n            scheduler.step()\n\n            train_losses.append(loss.mean().item())\n\n        val_losses = []\n        # transceiver.eval()\n        for b in tqdm(data_handler.val_dataloader):\n            encoder_idx = b[0].to(device)\n            encoder_attention_mask = b[1].to(device)\n\n            encoder_idx = data_handler.label_encoder.transform(encoder_idx)\n\n            d_sd = get_distance(args.d_min, args.d_max)\n            d_sr = get_distance(d_sd * args.gamma_min, d_sd * args.gamma_max)\n\n            with torch.no_grad():\n                _, loss = transceiver(\n                    input_ids=encoder_idx,\n                    attention_mask=encoder_attention_mask,\n                    d_sd=d_sd,\n                    d_sr=d_sr,\n                )\n            val_losses.append(loss.mean().item())\n\n        print(\"\\n\")\n        print_loss(train_losses, \"Train\")\n        print_loss(val_losses, \"Val\")\n\n        mean_loss = np.mean(val_losses)\n\n        checkpoint_path = os.path.join(\n            args.checkpoint_path,\n            f\"transceiver/transceiver_{epoch}.pt\",\n        )\n\n        if mean_loss < best_loss:\n            create_checkpoint(\n                path=checkpoint_path,\n                model_state_dict=transceiver.state_dict(),\n                optimizer_state_dict=optimizer.state_dict(),\n                scheduler_state_dict=scheduler.state_dict(),\n                mean_val_loss=mean_loss,\n                epoch=epoch,\n            )\n            best_loss = mean_loss\n        else:\n            create_checkpoint(\n                path=checkpoint_path,\n                model_state_dict=None,\n                optimizer_state_dict=None,\n                scheduler_state_dict=None,\n                mean_val_loss=mean_loss,\n                epoch=epoch,\n            )\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_end_to_end.py b/train_end_to_end.py
--- a/train_end_to_end.py	(revision d0e358a99a5c7b336d3b85eaafbfad7fec7347fc)
+++ b/train_end_to_end.py	(date 1715110671785)
@@ -12,7 +12,8 @@
     Transceiver,
     ChannelEncoder,
     ChannelDecoder,
-    init_dst_channel_decoder,
+    init_dst_channel_decoder_state_dict,
+    init_relay_semantic_encoder_state_dict,
 )
 from semantic_communication.utils.channel import (
     init_channel,
@@ -97,11 +98,10 @@
         label_encoder=data_handler.label_encoder,
         max_length=args.max_length,
         mode=args.mode if args.mode == "sentence" else "forward",
-        rate=args.rate,
+        rate=1 if args.mode == "sentence" else None,
     ).to(device)
-    relay_semantic_encoder.load_state_dict(
-        semantic_transformer.semantic_encoder.state_dict()
-    )
+    state_dict = init_relay_semantic_encoder_state_dict(semantic_transformer)
+    relay_semantic_encoder.load_state_dict(state_dict)
 
     relay_channel_encoder = ChannelEncoder(
         nin=args.channel_block_input_dim,
@@ -115,7 +115,7 @@
         nin=args.channel_block_latent_dim * 2,
         nout=args.channel_block_input_dim,
     ).to(device)
-    state_dict = init_dst_channel_decoder(semantic_transformer)
+    state_dict = init_dst_channel_decoder_state_dict(semantic_transformer)
     dst_channel_decoder.load_state_dict(state_dict, strict=False)
 
     dst_semantic_decoder = SemanticDecoder(
Index: semantic_communication/models/transceiver.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from typing import Optional, List\n\nimport torch\nfrom torch import nn\n\nfrom semantic_communication.models.semantic_decoder import SemanticDecoder\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.models.semantic_transformer import (\n    SemanticTransformer,\n    ChannelEncoder,\n    ChannelDecoder,\n)\nfrom semantic_communication.utils.channel import Channel\nfrom semantic_communication.utils.general import get_device, shift_inputs\n\n\n# class SrcRelayChannelModel(nn.Module):\n#     def __init__(self, n_in, n_latent, channel: Channel):\n#         super().__init__()\n#         self.relay_decoder = ChannelDecoder(n_latent, n_in)\n#         self.channel = channel\n#\n#     def forward(self, src_out, d_sr):\n#         ch_output = self.channel(src_out, d_sr)\n#         relay_in = self.relay_decoder(ch_output)\n#         return relay_in\n\n\n# class SrcRelayDstChannelModel(nn.Module):\n#     def __init__(\n#         self,\n#         n_in,\n#         n_latent,\n#         channel: Channel,\n#     ):\n#         super().__init__()\n#         self.relay_encoder = ChannelEncoder(n_in, n_latent)\n#         self.src_dst_decoder = ChannelDecoder(n_latent, n_in)\n#         self.relay_dst_decoder = ChannelDecoder(n_latent, n_in)\n#         self.channel = channel\n#\n#     def forward(self, src_out, rel_x, d_rd, d_sd):\n#         src_dst_in = self.channel(src_out, d_sd)\n#\n#         rel_out = self.relay_encoder(rel_x)\n#         rel_dst_in = self.channel(rel_out, d_rd)\n#\n#         x_hat = torch.cat(\n#             [self.relay_dst_decoder(rel_dst_in), self.src_dst_decoder(src_dst_in)],\n#             dim=-1,\n#         )\n#         return x_hat\n\n\n# class SrcRelayBlock(nn.Module):\n#     def __init__(\n#         self,\n#         semantic_transformer: SemanticTransformer,\n#         channel: Channel,\n#     ):\n#         super().__init__()\n#         self.semantic_encoder = semantic_transformer.semantic_encoder\n#         self.semantic_decoder = semantic_transformer.semantic_decoder\n#\n#         self.channel = channel\n#         self.src_channel_encoder = semantic_transformer.channel_encoder\n#         self.relay_channel_decoder = semantic_transformer.channel_decoder\n#\n#         self.device = get_device()\n#\n#     def forward(\n#         self,\n#         messages: Optional[List[str]] = None,\n#         input_ids: Optional[torch.Tensor] = None,\n#         attention_mask: Optional[torch.Tensor] = None,\n#         d_sr: Optional[float] = None,\n#     ):\n#         x = self.semantic_encoder(\n#             messages=messages,\n#             input_ids=input_ids,\n#             attention_mask=attention_mask,\n#         )\n#         x = self.src_channel_encoder(x)\n#         x = self._shift_relay_input(x)\n#\n#         x = self.channel(x, d_sr)\n#         x = self.relay_channel_decoder(x)\n#\n#         B, R, C = x.shape\n#         x = torch.repeat_interleave(input=x, repeats=R, dim=0)\n#\n#         enc_padding_mask = torch.tril(torch.ones(R, R, device=self.device), -1).T.bool()\n#         enc_padding_mask = enc_padding_mask.repeat(B, 1)\n#\n#         decoder_idx, targets, _, is_causal = shift_inputs(\n#             xb=input_ids,\n#             attention_mask=attention_mask,\n#             mode=self.semantic_encoder.mode,\n#             rate=R,\n#         )\n#\n#         decoder_idx = torch.repeat_interleave(input=decoder_idx, repeats=R, dim=0)\n#         targets = torch.repeat_interleave(input=targets, repeats=R, dim=0)\n#\n#         logits, loss = self.semantic_decoder(\n#             idx=decoder_idx,\n#             encoder_output=x,\n#             is_causal=is_causal,\n#             enc_padding_mask=enc_padding_mask,\n#             targets=targets,\n#         )\n#\n#         return logits, loss\n#\n#     @torch.no_grad()\n#     def generate(\n#         self,\n#         messages: Optional[List[str]] = None,\n#         input_ids: Optional[torch.Tensor] = None,\n#         attention_mask: Optional[torch.Tensor] = None,\n#         d_sr: Optional[float] = None,\n#     ):\n#         x = self.semantic_encoder(\n#             messages=messages,\n#             input_ids=input_ids,\n#             attention_mask=attention_mask,\n#         )\n#         x = self.src_channel_encoder(x)\n#         x = self._shift_relay_input(x)\n#\n#         x = self.channel(x, d_sr)\n#         x = self.relay_channel_decoder(x)\n#\n#         B, R, _ = x.shape\n#         x = torch.repeat_interleave(input=x, repeats=R, dim=0)\n#\n#         x_padding_mask = torch.tril(torch.ones(R, R, device=self.device), -1).T.bool()\n#         x_padding_mask = x_padding_mask.repeat(B, 1)\n#\n#         return self.semantic_decoder.generate(\n#             encoder_output=x,\n#             is_causal=False,\n#             max_length=self.semantic_encoder.max_length - 1,\n#             enc_padding_mask=x_padding_mask,\n#             n_generated_tokens=self.semantic_encoder.max_length,\n#         )\n#\n#     def _shift_relay_input(self, x):\n#         if self.semantic_encoder.mode == \"predict\":\n#             x = x[:, :-1, :]\n#         return x\n\n\nclass Transceiver(nn.Module):\n    def __init__(\n        self,\n        src_relay_transformer: SemanticTransformer,\n        relay_semantic_encoder: SemanticEncoder,\n        relay_channel_encoder: ChannelEncoder,\n        dst_channel_decoder: ChannelDecoder,\n        dst_semantic_decoder: SemanticDecoder,\n        channel: Channel,\n        max_length: int,\n    ):\n        super().__init__()\n        # source\n        self.src_semantic_encoder = src_relay_transformer.semantic_encoder\n        self.src_channel_encoder = src_relay_transformer.channel_encoder\n\n        # freeze source params\n        self._freeze(self.src_semantic_encoder)\n        self._freeze(self.src_channel_encoder)\n\n        # relay\n        self.relay_channel_decoder = src_relay_transformer.channel_decoder\n        self.relay_semantic_decoder = src_relay_transformer.semantic_decoder\n\n        # freeze relay decoding params\n        self._freeze(self.relay_channel_decoder)\n        self._freeze(self.relay_semantic_decoder)\n\n        self.relay_semantic_encoder = relay_semantic_encoder\n        self.relay_channel_encoder = relay_channel_encoder\n\n        # destination\n        self.dst_channel_decoder = dst_channel_decoder\n        self.dst_semantic_decoder = dst_semantic_decoder\n\n        self.channel = channel\n        self.max_length = max_length\n        self.device = get_device()\n\n    @staticmethod\n    def _freeze(m):\n        for p in m.parameters():\n            p.requires_grad = False\n\n    def forward(\n        self,\n        messages: Optional[List[str]] = None,\n        input_ids: Optional[torch.Tensor] = None,\n        attention_mask: Optional[torch.Tensor] = None,\n        d_sd: Optional[float] = None,\n        d_sr: Optional[float] = None,\n    ):\n        # source\n        x_src_to_dst, x_src_to_relay = self._source_forward(\n            attention_mask=attention_mask,\n            input_ids=input_ids,\n            messages=messages,\n        )\n\n        # relay\n        x_relay = self.channel(x_src_to_relay, d_sr)\n        x_relay = self._relay_forward(x_relay=x_relay)\n\n        # destination\n        x_dst1 = self.channel(x_relay, d_sd - d_sr)\n        x_dst2 = self.channel(x_src_to_dst, d_sd)\n        x_dst = torch.cat((x_dst1, x_dst2), dim=-1)\n\n        logits, loss = self._destination_forward(\n            x_dst=x_dst,\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n        )\n\n        return logits, loss\n\n    def _destination_forward(self, x_dst, input_ids, attention_mask):\n        x_dst = self.dst_channel_decoder(x_dst)\n        decoder_idx, targets, _, is_causal = shift_inputs(\n            xb=input_ids,\n            attention_mask=attention_mask,\n            mode=self.relay_semantic_encoder.mode,\n            rate=x_dst.shape[1],\n        )\n        logits, loss = self.dst_semantic_decoder(\n            idx=decoder_idx,\n            encoder_output=x_dst,\n            is_causal=is_causal,\n            enc_padding_mask=None,\n            targets=targets,\n        )\n        return logits, loss\n\n    def _relay_forward(self, x_relay):\n        x_relay = self.relay_channel_decoder(x_relay)\n        B, R, C = x_relay.shape\n\n        # decode every sentence embedding using beam search\n        x_relay = torch.repeat_interleave(input=x_relay, repeats=R, dim=0)\n        x_relay_padding_mask = torch.tril(\n            torch.ones(R, R, device=self.device), -1\n        ).T.bool()\n        x_relay_padding_mask = x_relay_padding_mask.repeat(B, 1)\n        x_relay, _ = self.relay_semantic_decoder.generate(\n            encoder_output=x_relay,\n            is_causal=self.relay_semantic_encoder.mode != \"sentence\",\n            max_length=self.max_length,  # TODO: fix +1 discrepancy\n            enc_padding_mask=x_relay_padding_mask,\n            n_generated_tokens=self.max_length + 1,\n        )\n\n        # create attention mask based on [SEP] token\n        relay_attention_mask = torch.ones(\n            *x_relay.shape, dtype=torch.long, device=self.device\n        )\n        for i in range(x_relay.shape[0]):\n            k = torch.argmax((x_relay[i] == 2).long()).item()\n            if k == 0:\n                continue\n            relay_attention_mask[i, k + 1 :] = 0\n\n        # re-encode decoded sentences and forward\n        x_relay = self.relay_semantic_encoder(\n            input_ids=x_relay,\n            attention_mask=relay_attention_mask,\n        )\n        x_relay = x_relay[torch.arange(B * R), torch.arange(R).repeat(B), :]\n        x_relay = x_relay.reshape(B, R, C)\n        x_relay = self.relay_channel_encoder(x_relay)\n        return x_relay\n\n    def _source_forward(self, input_ids, messages, attention_mask):\n        x_src = self.src_semantic_encoder(\n            messages=messages,\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n        )\n        x_src = self.src_channel_encoder(x_src)\n        x_src_to_relay, x_src_to_dst = self._shift_src_output(x_src)\n        return x_src_to_dst, x_src_to_relay\n\n    def generate(\n        self,\n        messages: Optional[List[str]] = None,\n        input_ids: Optional[torch.Tensor] = None,\n        attention_mask: Optional[torch.Tensor] = None,\n        d_sd: Optional[float] = None,\n        d_sr: Optional[float] = None,\n    ):\n        self.eval()\n        with torch.no_grad():\n            # source\n            x_src_to_dst, x_src_to_relay = self._source_forward(\n                attention_mask=attention_mask,\n                input_ids=input_ids,\n                messages=messages,\n            )\n\n            # relay\n            x_relay = self.channel(x_src_to_relay, d_sr)\n            x_relay = self._relay_forward(x_relay=x_relay)\n\n            # destination\n            x_dst1 = self.channel(x_relay, d_sd - d_sr)\n            x_dst2 = self.channel(x_src_to_dst, d_sd)\n            x_dst = torch.cat((x_dst1, x_dst2), dim=-1)\n\n            x_dst = self.dst_channel_decoder(x_dst)\n            return self.dst_semantic_decoder.generate(\n                encoder_output=x_dst,\n                is_causal=False,\n                max_length=self.max_length,\n                enc_padding_mask=None,\n                n_generated_tokens=self.max_length + 1,\n            )\n\n    def _shift_src_output(self, src_out):\n        if self.relay_semantic_encoder.mode == \"predict\":\n            src_to_relay = src_out[:, :-1, :]\n            src_to_dst = src_out[:, 1:, :]\n        else:\n            src_to_relay = src_out\n            src_to_dst = src_out\n\n        return src_to_relay, src_to_dst\n\n\ndef init_dst_channel_decoder(semantic_transformer):\n    state_dict = semantic_transformer.channel_decoder.state_dict()\n    state_dict[\"layers.0.linear.weight\"] = state_dict[\"layers.1.linear.weight\"].repeat(\n        1, 2\n    )\n    state_dict[\"layers.0.linear.bias\"] = state_dict[\"layers.1.linear.bias\"]\n    state_dict[\"layers.0.ln.weight\"] = state_dict[\"layers.1.ln.weight\"]\n    state_dict[\"layers.0.ln.bias\"] = state_dict[\"layers.1.ln.bias\"]\n    state_dict[\"layers.0.prelu.weight\"] = state_dict[\"layers.1.prelu.weight\"]\n    return state_dict\n\n\n# class RelayEncoder:\n#     def __init__(\n#         self,\n#         semantic_encoder: SemanticEncoder,\n#         label_encoder: TensorLabelEncoder,\n#     ):\n#         super().__init__()\n#         self.device = get_device()\n#         self.semantic_encoder = semantic_encoder\n#         self.label_encoder = label_encoder\n#\n#     def __call__(self, logits):\n#         B, T, _ = logits.shape\n#         predicted_ids = torch.argmax(logits, dim=-1)\n#\n#         # append [CLS] token\n#         cls_padding = torch.full((B, 1), self.label_encoder.cls_id).to(self.device)\n#         predicted_ids = torch.cat(\n#             tensors=(cls_padding, predicted_ids),\n#             dim=1,\n#         )\n#\n#         # transform to bert token ids\n#         predicted_ids = self.label_encoder.inverse_transform(predicted_ids)\n#\n#         # ids are repeated to generate the embeddings sequentially\n#         predicted_ids = torch.repeat_interleave(predicted_ids, T, dim=0)\n#\n#         # tril mask to generate the embeddings sequentially\n#         tril_mask = (\n#             torch.tril(\n#                 torch.ones(T, T + 1, dtype=torch.long),\n#                 diagonal=1,\n#             ).repeat(B, 1)\n#         ).to(self.device)\n#\n#         out = self.semantic_encoder(\n#             input_ids=predicted_ids,\n#             attention_mask=tril_mask,\n#         )\n#\n#         # use eye mask to select the correct embeddings sequentially\n#         eye_mask = (torch.eye(T).repeat(1, B) == 1).to(self.device)\n#         out = torch.masked_select(out[:, 1:, :].transpose(-1, 0), eye_mask)\n#         out = out.view(B, T, -1)\n#\n#         return out\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/semantic_communication/models/transceiver.py b/semantic_communication/models/transceiver.py
--- a/semantic_communication/models/transceiver.py	(revision d0e358a99a5c7b336d3b85eaafbfad7fec7347fc)
+++ b/semantic_communication/models/transceiver.py	(date 1715111029905)
@@ -250,15 +250,15 @@
 
         # decode every sentence embedding using beam search
         x_relay = torch.repeat_interleave(input=x_relay, repeats=R, dim=0)
-        x_relay_padding_mask = torch.tril(
+        causal_padding_mask = torch.tril(
             torch.ones(R, R, device=self.device), -1
         ).T.bool()
-        x_relay_padding_mask = x_relay_padding_mask.repeat(B, 1)
+        causal_padding_mask = causal_padding_mask.repeat(B, 1)
         x_relay, _ = self.relay_semantic_decoder.generate(
             encoder_output=x_relay,
             is_causal=self.relay_semantic_encoder.mode != "sentence",
             max_length=self.max_length,  # TODO: fix +1 discrepancy
-            enc_padding_mask=x_relay_padding_mask,
+            enc_padding_mask=causal_padding_mask,
             n_generated_tokens=self.max_length + 1,
         )
 
@@ -338,7 +338,13 @@
         return src_to_relay, src_to_dst
 
 
-def init_dst_channel_decoder(semantic_transformer):
+def init_relay_semantic_encoder_state_dict(semantic_transformer):
+    state_dict = semantic_transformer.semantic_encoder.state_dict()
+    state_dict["pooling_head"] = state_dict["pooling_head"][:, [0]]
+    return state_dict
+
+
+def init_dst_channel_decoder_state_dict(semantic_transformer):
     state_dict = semantic_transformer.channel_decoder.state_dict()
     state_dict["layers.0.linear.weight"] = state_dict["layers.1.linear.weight"].repeat(
         1, 2
