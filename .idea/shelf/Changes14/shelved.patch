Index: train_source_coding.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_source_coding.py b/train_source_coding.py
new file mode 100644
--- /dev/null	(date 1703745683328)
+++ b/train_source_coding.py	(date 1703745683328)
@@ -0,0 +1,154 @@
+import argparse
+import os
+
+import numpy as np
+from tqdm import tqdm
+import torch
+
+from semantic_communication.data_processing.data_handler import DataHandler
+from semantic_communication.models.codec import Codec
+from semantic_communication.models.semantic_decoder_v2 import SemanticDecoder
+from semantic_communication.models.semantic_encoder import SemanticEncoder
+from semantic_communication.models.transceiver import ChannelEncoder
+from semantic_communication.utils.general import (
+    get_device,
+    print_loss,
+    create_checkpoint,
+    set_seed,
+    add_semantic_decoder_args,
+    add_data_args,
+    add_train_args,
+    shift_inputs,
+    load_model,
+    load_optimizer,
+)
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument("--codec-path", default=None, type=str)
+    parser.add_argument("--relay-decoder-path", default=None, type=str)
+    parser.add_argument("--source_code_dim", type=int)
+    add_semantic_decoder_args(parser)
+    add_data_args(parser)
+    add_train_args(parser)
+    args = parser.parse_args()
+
+    set_seed()
+    device = get_device()
+
+    semantic_encoder = SemanticEncoder(max_length=args.max_length)
+    data_handler = DataHandler(
+        semantic_encoder=semantic_encoder,
+        batch_size=args.batch_size,
+        data_fp=args.data_fp,
+    )
+
+    encoder = ChannelEncoder(nin=args.n_embeddings, nout=args.source_code_dim)
+    semantic_decoder = SemanticDecoder(
+        vocab_size=data_handler.vocab_size,
+        n_blocks=args.n_blocks,
+        n_heads=args.n_heads,
+        n_embeddings=args.n_embeddings,
+        block_size=args.max_length,
+        semantic_encoder=semantic_encoder,
+        label_encoder=data_handler.label_encoder,
+    ).to(device)
+    load_model(semantic_decoder, args.relay_decoder_path)
+
+    codec = Codec(
+        encoder=encoder,
+        decoder=semantic_decoder,
+        encoder_out_dim=args.source_code_dim,
+        embedding_dim=args.n_embeddings,
+    )
+    load_model(codec, args.codec_path)
+
+    optimizer = torch.optim.AdamW(codec.parameters(), lr=args.lr)
+    load_optimizer(optimizer, args.codec_path)
+
+    best_loss = torch.inf
+    for epoch in range(args.n_epochs):
+        train_losses = []
+        codec.train()
+        for b in tqdm(data_handler.train_dataloader):
+            xb = b[0].to(device)
+            attention_mask = b[1].to(device)
+
+            encoder_output = semantic_encoder(
+                input_ids=xb,
+                attention_mask=attention_mask,
+            )
+            xb = data_handler.label_encoder.transform(xb)
+            idx, encoder_output, attention_mask, targets = shift_inputs(
+                xb=xb,
+                encoder_output=encoder_output,
+                attention_mask=attention_mask,
+                mode=args.mode,
+            )
+            _, loss = codec(
+                idx=idx,
+                x=encoder_output,
+                attention_mask=attention_mask,
+                targets=targets,
+            )
+
+            optimizer.zero_grad(set_to_none=True)
+            loss.backward()
+            optimizer.step()
+
+            train_losses.append(loss.item())
+
+        val_losses = []
+        codec.eval()
+        for b in data_handler.val_dataloader:
+            xb = b[0].to(device)
+            attention_mask = b[1].to(device)
+
+            encoder_output = semantic_encoder(
+                input_ids=xb,
+                attention_mask=attention_mask,
+            )
+            xb = data_handler.label_encoder.transform(xb)
+            idx, encoder_output, attention_mask, targets = shift_inputs(
+                xb=xb,
+                encoder_output=encoder_output,
+                attention_mask=attention_mask,
+                mode=args.mode,
+            )
+
+            with torch.no_grad():
+                _, loss = codec(
+                    idx=idx,
+                    x=encoder_output,
+                    attention_mask=attention_mask,
+                    targets=targets,
+                )
+            val_losses.append(loss.item())
+
+        print("\n")
+        print_loss(train_losses, "Train")
+        print_loss(val_losses, "Val")
+
+        mean_loss = np.mean(val_losses)
+
+        checkpoint_path = os.path.join(
+            args.checkpoint_path,
+            f"codec/codec_{epoch}.pt",
+        )
+
+        if mean_loss < best_loss:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=codec.state_dict(),
+                optimizer_state_dict=optimizer.state_dict(),
+                mean_val_loss=mean_loss,
+            )
+            best_loss = mean_loss
+        else:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=None,
+                optimizer_state_dict=None,
+                mean_val_loss=mean_loss,
+            )
