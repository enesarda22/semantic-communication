Index: train_tx_relay_channel_block.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\n\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\n\nfrom semantic_communication.data_processing.data_handler import DataHandler\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.models.transceiver import TxRelayChannelModel\nfrom semantic_communication.utils.channel import AWGN, Rayleigh\nfrom semantic_communication.utils.general import (\n    get_device,\n    print_loss,\n    create_checkpoint,\n)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--checkpoint-path\", default=\"checkpoints\", type=str)\n    parser.add_argument(\"--n-samples\", default=10000, type=int)\n    parser.add_argument(\"--train-size\", default=0.9, type=float)\n    parser.add_argument(\"--val-size\", default=0.2, type=float)\n    parser.add_argument(\"--max-length\", default=30, type=int)\n    parser.add_argument(\"--batch-size\", default=32, type=int)\n    parser.add_argument(\"--n-epochs\", default=10, type=int)\n    parser.add_argument(\"--lr\", default=1e-4, type=float)\n    parser.add_argument(\"--n-heads\", default=4, type=int)\n    parser.add_argument(\"--n-embeddings\", default=384, type=int)\n\n    # New args\n    parser.add_argument(\"--channel-block-input-dim\", default=384, type=int)\n    parser.add_argument(\"--channel-block-latent-dim\", default=128, type=int)\n    parser.add_argument(\"--sig-pow\", default=1.0, type=float)\n    parser.add_argument(\"--SNR-min\", default=3, type=int)\n    parser.add_argument(\"--SNR-max\", default=21, type=int)\n    parser.add_argument(\"--SNR-step\", default=3, type=int)\n    parser.add_argument(\"--SNR-window\", default=5, type=int)\n    parser.add_argument(\"--channel-type\", default=\"AWGN\", type=str)\n    args = parser.parse_args()\n\n    device = get_device()\n\n    semantic_encoder = SemanticEncoder(max_length=args.max_length)\n    data_handler = DataHandler(\n        semantic_encoder=semantic_encoder,\n        batch_size=args.batch_size,\n        n_samples=args.n_samples,\n        train_size=args.train_size,\n        val_size=args.val_size\n    )\n    data_handler.load_data()\n\n    # Initializations\n    SNR_dB = np.flip(np.arange(args.SNR_min, args.SNR_max + 1, args.SNR_step))\n\n    if args.channel_type == \"AWGN\":\n        channel = AWGN(SNR_dB[0], args.sig_pow)\n    else:\n        channel = Rayleigh(SNR_dB[0], args.sig_pow)\n\n    tx_relay_channel_model = TxRelayChannelModel(nin=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel=channel).to(device)\n\n    optimizer = torch.optim.AdamW(\n        params=tx_relay_channel_model.parameters(),\n        lr=args.lr,\n    )\n    criterion = torch.nn.MSELoss()\n\n    best_loss = 5\n    cur_win, cur_SNR_index = 0, 0\n\n    for epoch in range(args.n_epochs):\n        train_losses = []\n        tx_relay_channel_model.train()\n        if cur_win >= args.SNR_window:\n            cur_win = 0\n            if not cur_SNR_index >= len(SNR_dB) - 1:\n                cur_SNR_index += 1\n\n            if args.channel_type == \"AWGN\":\n                channel = AWGN(SNR_dB[cur_SNR_index], args.sig_pow)\n            else:\n                channel = Rayleigh(SNR_dB[cur_SNR_index], args.sig_pow)\n\n            tx_relay_channel_model.channel = channel\n\n        cur_win += 1\n        for b in tqdm(data_handler.train_dataloader):\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            encoder_output = semantic_encoder(\n                input_ids=xb,\n                attention_mask=attention_mask,\n            )\n            encoder_output_hat = tx_relay_channel_model(encoder_output)\n            loss = criterion(encoder_output_hat, encoder_output)\n\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss.item())\n\n        val_losses = []\n        tx_relay_channel_model.eval()\n        for b in data_handler.val_dataloader:\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            encoder_output = semantic_encoder(\n                input_ids=xb,\n                attention_mask=attention_mask,\n            )\n\n            with torch.no_grad():\n                encoder_output_hat = tx_relay_channel_model(encoder_output)\n\n            loss = criterion(encoder_output_hat, encoder_output)\n            val_losses.append(loss.item())\n\n        print(\"\\n\")\n        print_loss(train_losses, \"Train\")\n        print_loss(val_losses, \"Val\")\n\n        mean_loss = np.mean(val_losses)\n\n        if mean_loss < best_loss:\n            create_checkpoint(\n                path=os.path.join(\n                    args.checkpoint_path,\n                    f\"tx-relay-channel/tx_relay_channel_{epoch}.pt\",\n                ),\n                model_state_dict=tx_relay_channel_model.state_dict(),\n                optimizer_state_dict=optimizer.state_dict(),\n                mean_val_loss=mean_loss,\n            )\n            best_loss = mean_loss\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_tx_relay_channel_block.py b/train_tx_relay_channel_block.py
--- a/train_tx_relay_channel_block.py	(revision 1c9506dff07f9306ee05d03ab11a86d6e02a646d)
+++ b/train_tx_relay_channel_block.py	(date 1698877493408)
@@ -47,7 +47,7 @@
         batch_size=args.batch_size,
         n_samples=args.n_samples,
         train_size=args.train_size,
-        val_size=args.val_size
+        val_size=args.val_size,
     )
     data_handler.load_data()
 
@@ -59,7 +59,11 @@
     else:
         channel = Rayleigh(SNR_dB[0], args.sig_pow)
 
-    tx_relay_channel_model = TxRelayChannelModel(nin=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel=channel).to(device)
+    tx_relay_channel_model = TxRelayChannelModel(
+        nin=args.channel_block_input_dim,
+        n_latent=args.channel_block_latent_dim,
+        channel=channel,
+    ).to(device)
 
     optimizer = torch.optim.AdamW(
         params=tx_relay_channel_model.parameters(),
@@ -125,14 +129,23 @@
 
         mean_loss = np.mean(val_losses)
 
-        if mean_loss < best_loss:
-            create_checkpoint(
-                path=os.path.join(
-                    args.checkpoint_path,
-                    f"tx-relay-channel/tx_relay_channel_{epoch}.pt",
-                ),
-                model_state_dict=tx_relay_channel_model.state_dict(),
+        checkpoint_path = os.path.join(
+            args.checkpoint_path,
+            f"tx-relay-channel/tx_relay_channel_{epoch}.pt",
+        )
+
+        if mean_loss < best_loss:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=relay_decoder.state_dict(),
                 optimizer_state_dict=optimizer.state_dict(),
                 mean_val_loss=mean_loss,
             )
             best_loss = mean_loss
+        else:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=None,
+                optimizer_state_dict=None,
+                mean_val_loss=mean_loss,
+            )
Index: README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># semantic-communication\n\n## semantic decoder\n\nmulti head = 64 * 64 * 3 * 6 = 73_728\nfeed forward = 2 * 384 * 4 * 384 = 104_448\nx6 = 1_069_056\n\nlinear = 30522 * 384 = 11_720_448\n\nn_heads = 6\nn_decoder_block = 6\n\n### training\nn_samples = 50_000\nlr =  4e-5\nepoch = 20\nbatch_size = 64\n\n## channel\nn_latent = 128, 256\nmin_SNR = 3\nmax_SNR = 21\nSNR_step = 3\nSNR_window = 3\n\n### training\nn_samples = 50_000\nlr = 4e-6\nepoch = 25\nbatch_size = 64\n\n## channel2\nSNR_diff = 3\n\n### receiver_decoder\nsame as relay decoder\n\n## end to end\nlr = 1e-6\nepoch = 15\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/README.md b/README.md
--- a/README.md	(revision 1c9506dff07f9306ee05d03ab11a86d6e02a646d)
+++ b/README.md	(date 1698877929998)
@@ -17,12 +17,36 @@
 epoch = 20
 batch_size = 64
 
+```
+python train_relay_decoder.py \
+--n-samples 50000 \
+--batch-size 64 \
+--n-epochs 20 \
+--lr 4e-5 \
+--n-blocks 6 \
+--n-heads 6
+```
+
+
+```
+python train_receiver_decoder.py \
+--relay-decoder-path checkpoints/**.pt \
+--n-samples 50000 \
+--batch-size 64 \
+--n-epochs 20 \
+--lr 4e-5 \
+--n-blocks 6 \
+--n-heads 6
+```
+
+
 ## channel
 n_latent = 128, 256
 min_SNR = 3
 max_SNR = 21
 SNR_step = 3
 SNR_window = 3
+channel_type = AWGN
 
 ### training
 n_samples = 50_000
@@ -30,12 +54,63 @@
 epoch = 25
 batch_size = 64
 
+```
+python train_tx_relay_channel_block.py \
+--n-samples 50000 \
+--batch-size 64 \
+--n-epochs 25 \
+--lr 4e-6 \
+--channel-block-latent-dim 128 \
+--SNR-min 3 \
+--SNR-max 21 \
+--SNR-step 3 \
+--SNR-window 3 \
+--channel-type AWGN
+```
+
+
 ## channel2
 SNR_diff = 3
 
-### receiver_decoder
-same as relay decoder
+```
+python train_tx_relay_rx_channel_block.py \
+--relay-decoder-path checkpoints/**.pt \
+--n-blocks 6 \
+--n-heads 6 \
+--n-samples 50000 \
+--batch-size 64 \
+--n-epochs 25 \
+--lr 4e-6 \
+--channel-block-latent-dim 128 \
+--SNR-min 3 \
+--SNR-max 21 \
+--SNR-step 3 \
+--SNR-window 3 \
+--channel-type AWGN \
+--SNR-diff 3
+```
 
 ## end to end
 lr = 1e-6
 epoch = 15
+
+```
+python train_tx_relay_rx_channel_block.py \
+--relay-decoder-path checkpoints/**.pt \
+--receiver-decoder-path checkpoints/**.pt \
+--n-blocks 6 \
+--n-heads 6 \
+--tx-relay-channel-model-path checkpoints/**.pt \
+--tx-relay-rx-channel-model-path checkpoints/**.pt \
+--n-samples 50000 \
+--batch-size 64 \
+--n-epochs 25 \
+--lr 1e-6 \
+--channel-block-latent-dim 128 \
+--SNR-min 3 \
+--SNR-max 21 \
+--SNR-step 3 \
+--SNR-window 3 \
+--channel-type AWGN \
+--SNR-diff 3
+```
Index: train_tx_relay_rx_channel_block.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\n\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\n\nfrom semantic_communication.data_processing.data_handler import DataHandler\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.models.transceiver import (\n    TxRelayRxChannelModel,\n    Relay,\n)\nfrom semantic_communication.utils.channel import AWGN, Rayleigh\nfrom semantic_communication.models.semantic_decoder import SemanticDecoder\nfrom semantic_communication.utils.general import (\n    get_device,\n    print_loss,\n    create_checkpoint,\n)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--relay-decoder-path\", type=str)\n    parser.add_argument(\"--checkpoint-path\", default=\"checkpoints\", type=str)\n    parser.add_argument(\"--n-samples\", default=10000, type=int)\n    parser.add_argument(\"--train-size\", default=0.9, type=float)\n    parser.add_argument(\"--val-size\", default=0.2, type=float)\n    parser.add_argument(\"--max-length\", default=30, type=int)\n    parser.add_argument(\"--batch-size\", default=32, type=int)\n    parser.add_argument(\"--n-epochs\", default=10, type=int)\n    parser.add_argument(\"--lr\", default=1e-4, type=float)\n    parser.add_argument(\"--n-blocks\", default=1, type=int)\n    parser.add_argument(\"--n-heads\", default=4, type=int)\n    parser.add_argument(\"--n-embeddings\", default=384, type=int)\n\n    # New args\n    parser.add_argument(\"--channel-block-input-dim\", default=384, type=int)\n    parser.add_argument(\"--channel-block-latent-dim\", default=128, type=int)\n    parser.add_argument(\"--sig-pow\", default=1.0, type=float)\n    parser.add_argument(\"--SNR-min\", default=3, type=int)\n    parser.add_argument(\"--SNR-max\", default=21, type=int)\n    parser.add_argument(\"--SNR-step\", default=3, type=int)\n    parser.add_argument(\"--SNR-window\", default=5, type=int)\n    parser.add_argument(\"--SNR-diff\", default=3, type=int)\n    parser.add_argument(\"--channel-type\", default=\"AWGN\", type=str)\n    args = parser.parse_args()\n\n    device = get_device()\n\n    semantic_encoder = SemanticEncoder(max_length=args.max_length)\n    data_handler = DataHandler(\n        semantic_encoder=semantic_encoder,\n        batch_size=args.batch_size,\n        n_samples=args.n_samples,\n        train_size=args.train_size,\n        val_size=args.val_size\n    )\n    data_handler.load_data()\n\n    relay_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n    ).to(device)\n    checkpoint = torch.load(args.relay_decoder_path)\n    relay_decoder.load_state_dict(checkpoint[\"model_state_dict\"])\n\n    relay = Relay(\n        semantic_encoder=semantic_encoder,\n        semantic_decoder=relay_decoder,\n    )\n\n    # Initializations\n    SNR_dB = np.flip(np.arange(args.SNR_min, args.SNR_max + 1, args.SNR_step))\n\n    if args.channel_type == \"AWGN\":\n        channel_tx_rx = AWGN(SNR_dB[0] - args.SNR_diff, args.sig_pow)\n        channel_rel_rx = AWGN(SNR_dB[0], args.sig_pow)\n    else:\n        channel_tx_rx = Rayleigh(SNR_dB[0] - args.SNR_diff, args.sig_pow)\n        channel_rel_rx = Rayleigh(SNR_dB[0], args.sig_pow)\n\n    tx_relay_rx_channel_model = TxRelayRxChannelModel(\n        nin=args.channel_block_input_dim,\n        n_latent=args.channel_block_latent_dim,\n        channel_tx_rx=channel_tx_rx,\n        channel_rel_rx=channel_rel_rx,\n    ).to(device)\n\n    optimizer = torch.optim.AdamW(\n        params=tx_relay_rx_channel_model.parameters(),\n        lr=args.lr,\n    )\n    criterion = torch.nn.MSELoss()\n\n    best_loss = 5\n    cur_win, cur_SNR_index = 0, 0\n\n    for epoch in range(args.n_epochs):\n        train_losses = []\n        tx_relay_rx_channel_model.train()\n        if cur_win >= args.SNR_window:\n            cur_win = 0\n            if not cur_SNR_index >= len(SNR_dB) - 1:\n                cur_SNR_index += 1\n\n            if args.channel_type == \"AWGN\":\n                channel_tx_rx = AWGN(\n                    SNR_dB[cur_SNR_index] - args.SNR_diff, args.sig_pow\n                )\n                channel_rel_rx = AWGN(SNR_dB[cur_SNR_index], args.sig_pow)\n            else:\n                channel_tx_rx = Rayleigh(\n                    SNR_dB[cur_SNR_index] - args.SNR_diff, args.sig_pow\n                )\n                channel_rel_rx = Rayleigh(\n                    SNR_dB[cur_SNR_index], args.sig_pow\n                )\n\n            tx_relay_rx_channel_model.channel_tx_rx = channel_tx_rx\n            tx_relay_rx_channel_model.channel_rel_rx = channel_rel_rx\n\n        cur_win += 1\n        for b in tqdm(data_handler.train_dataloader):\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            encoder_output = semantic_encoder(\n                input_ids=xb,\n                attention_mask=attention_mask,\n            )\n            relay_out = relay(\n                x=encoder_output[:, :-1, :]\n            )\n\n            output_hat = tx_relay_rx_channel_model(\n                encoder_output[:, 1:, :], relay_out\n            )\n            loss = criterion(output_hat, encoder_output[:, 1:, :] + relay_out)\n\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss.item())\n\n        val_losses = []\n        tx_relay_rx_channel_model.eval()\n        for b in data_handler.val_dataloader:\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            encoder_output = semantic_encoder(\n                input_ids=xb,\n                attention_mask=attention_mask,\n            )\n            relay_out = relay(\n                x=encoder_output[:, :-1, :]\n            )\n\n            with torch.no_grad():\n                output_hat = tx_relay_rx_channel_model(\n                    encoder_output[:, 1:, :], relay_out\n                )\n\n            loss = criterion(output_hat, encoder_output[:, 1:, :] + relay_out)\n            val_losses.append(loss.item())\n\n        print(\"\\n\")\n        print_loss(train_losses, \"Train\")\n        print_loss(val_losses, \"Val\")\n\n        mean_loss = np.mean(val_losses)\n        if mean_loss < best_loss:\n            create_checkpoint(\n                path=os.path.join(\n                    args.checkpoint_path,\n                    f\"tx-relay-rx-channel/tx_relay_rx_channel_{epoch}.pt\",\n                ),\n                model_state_dict=tx_relay_rx_channel_model.state_dict(),\n                optimizer_state_dict=optimizer.state_dict(),\n                mean_val_loss=mean_loss,\n            )\n            best_loss = mean_loss\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_tx_relay_rx_channel_block.py b/train_tx_relay_rx_channel_block.py
--- a/train_tx_relay_rx_channel_block.py	(revision 1c9506dff07f9306ee05d03ab11a86d6e02a646d)
+++ b/train_tx_relay_rx_channel_block.py	(date 1698877594115)
@@ -54,7 +54,7 @@
         batch_size=args.batch_size,
         n_samples=args.n_samples,
         train_size=args.train_size,
-        val_size=args.val_size
+        val_size=args.val_size,
     )
     data_handler.load_data()
 
@@ -116,9 +116,7 @@
                 channel_tx_rx = Rayleigh(
                     SNR_dB[cur_SNR_index] - args.SNR_diff, args.sig_pow
                 )
-                channel_rel_rx = Rayleigh(
-                    SNR_dB[cur_SNR_index], args.sig_pow
-                )
+                channel_rel_rx = Rayleigh(SNR_dB[cur_SNR_index], args.sig_pow)
 
             tx_relay_rx_channel_model.channel_tx_rx = channel_tx_rx
             tx_relay_rx_channel_model.channel_rel_rx = channel_rel_rx
@@ -132,9 +130,7 @@
                 input_ids=xb,
                 attention_mask=attention_mask,
             )
-            relay_out = relay(
-                x=encoder_output[:, :-1, :]
-            )
+            relay_out = relay(x=encoder_output[:, :-1, :])
 
             output_hat = tx_relay_rx_channel_model(
                 encoder_output[:, 1:, :], relay_out
@@ -156,9 +152,7 @@
                 input_ids=xb,
                 attention_mask=attention_mask,
             )
-            relay_out = relay(
-                x=encoder_output[:, :-1, :]
-            )
+            relay_out = relay(x=encoder_output[:, :-1, :])
 
             with torch.no_grad():
                 output_hat = tx_relay_rx_channel_model(
@@ -173,14 +167,24 @@
         print_loss(val_losses, "Val")
 
         mean_loss = np.mean(val_losses)
-        if mean_loss < best_loss:
-            create_checkpoint(
-                path=os.path.join(
-                    args.checkpoint_path,
-                    f"tx-relay-rx-channel/tx_relay_rx_channel_{epoch}.pt",
-                ),
-                model_state_dict=tx_relay_rx_channel_model.state_dict(),
+
+        checkpoint_path = os.path.join(
+            args.checkpoint_path,
+            f"tx-relay-rx-channel/tx_relay_rx_channel_{epoch}.pt",
+        )
+
+        if mean_loss < best_loss:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=relay_decoder.state_dict(),
                 optimizer_state_dict=optimizer.state_dict(),
                 mean_val_loss=mean_loss,
             )
             best_loss = mean_loss
+        else:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=None,
+                optimizer_state_dict=None,
+                mean_val_loss=mean_loss,
+            )
Index: train_receiver_decoder.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\n\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\n\nfrom semantic_communication.data_processing.data_handler import DataHandler\nfrom semantic_communication.models.semantic_decoder import SemanticDecoder\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.models.transceiver import Relay\nfrom semantic_communication.utils.general import (\n    get_device,\n    print_loss,\n    create_checkpoint,\n)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--relay-decoder-path\", type=str)\n    parser.add_argument(\"--checkpoint-path\", default=\"checkpoints\", type=str)\n    parser.add_argument(\"--n-samples\", default=10000, type=int)\n    parser.add_argument(\"--train-size\", default=0.9, type=float)\n    parser.add_argument(\"--val-size\", default=0.2, type=float)\n    parser.add_argument(\"--max-length\", default=30, type=int)\n    parser.add_argument(\"--batch-size\", default=32, type=int)\n    parser.add_argument(\"--n-epochs\", default=10, type=int)\n    parser.add_argument(\"--lr\", default=1e-4, type=float)\n    parser.add_argument(\"--n-blocks\", default=1, type=int)\n    parser.add_argument(\"--n-heads\", default=4, type=int)\n    parser.add_argument(\"--n-embeddings\", default=384, type=int)\n    args = parser.parse_args()\n\n    device = get_device()\n\n    semantic_encoder = SemanticEncoder(max_length=args.max_length)\n    data_handler = DataHandler(\n        semantic_encoder=semantic_encoder,\n        batch_size=args.batch_size,\n        n_samples=args.n_samples,\n        train_size=args.train_size,\n        val_size=args.val_size\n    )\n    data_handler.load_data()\n\n    relay_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n    ).to(device)\n    checkpoint = torch.load(args.relay_decoder_path)\n    relay_decoder.load_state_dict(checkpoint[\"model_state_dict\"])\n    relay_decoder.to(device)\n\n\n    relay = Relay(\n        semantic_encoder=semantic_encoder,\n        semantic_decoder=relay_decoder,\n    ).to(device)\n    receiver_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n    ).to(device)\n    optimizer = torch.optim.AdamW(receiver_decoder.parameters(), lr=args.lr)\n\n    best_loss = 5\n    for epoch in range(args.n_epochs):\n        train_losses = []\n        receiver_decoder.train()\n        for b in tqdm(data_handler.train_dataloader):\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            encoder_output = semantic_encoder(\n                input_ids=xb,\n                attention_mask=attention_mask,\n            )\n            relay_out = relay(\n                x=encoder_output[:, :-1, :]\n            )\n            superposed_out = relay_out + encoder_output[:, 1:, :]\n            logits, loss = receiver_decoder(\n                encoder_output=superposed_out,\n                attention_mask=attention_mask[:, 1:],\n                targets=xb[:, 1:],\n            )\n\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n\n            train_losses.append(loss.item())\n\n        val_losses = []\n        receiver_decoder.eval()\n        for b in data_handler.val_dataloader:\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            encoder_output = semantic_encoder(\n                input_ids=xb,\n                attention_mask=attention_mask,\n            )\n            relay_out = relay(\n                x=encoder_output[:, :-1, :]\n            )\n            superposed_out = relay_out + encoder_output[:, 1:, :]\n\n            with torch.no_grad():\n                _, loss = receiver_decoder(\n                    encoder_output=superposed_out,\n                    attention_mask=attention_mask[:, 1:],\n                    targets=xb[:, 1:],\n                )\n            val_losses.append(loss.item())\n\n        print(\"\\n\")\n        print_loss(train_losses, \"Train\")\n        print_loss(val_losses, \"Val\")\n\n        mean_loss = np.mean(val_losses)\n        if mean_loss < best_loss:\n            create_checkpoint(\n                path=os.path.join(\n                    args.checkpoint_path,\n                    f\"receiver-decoder/receiver_decoder_{epoch}.pt\",\n                ),\n                model_state_dict=receiver_decoder.state_dict(),\n                optimizer_state_dict=optimizer.state_dict(),\n                mean_val_loss=mean_loss,\n            )\n            best_loss = mean_loss\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_receiver_decoder.py b/train_receiver_decoder.py
--- a/train_receiver_decoder.py	(revision 1c9506dff07f9306ee05d03ab11a86d6e02a646d)
+++ b/train_receiver_decoder.py	(date 1698877265016)
@@ -40,7 +40,7 @@
         batch_size=args.batch_size,
         n_samples=args.n_samples,
         train_size=args.train_size,
-        val_size=args.val_size
+        val_size=args.val_size,
     )
     data_handler.load_data()
 
@@ -55,7 +55,6 @@
     relay_decoder.load_state_dict(checkpoint["model_state_dict"])
     relay_decoder.to(device)
 
-
     relay = Relay(
         semantic_encoder=semantic_encoder,
         semantic_decoder=relay_decoder,
@@ -81,9 +80,7 @@
                 input_ids=xb,
                 attention_mask=attention_mask,
             )
-            relay_out = relay(
-                x=encoder_output[:, :-1, :]
-            )
+            relay_out = relay(x=encoder_output[:, :-1, :])
             superposed_out = relay_out + encoder_output[:, 1:, :]
             logits, loss = receiver_decoder(
                 encoder_output=superposed_out,
@@ -107,9 +104,7 @@
                 input_ids=xb,
                 attention_mask=attention_mask,
             )
-            relay_out = relay(
-                x=encoder_output[:, :-1, :]
-            )
+            relay_out = relay(x=encoder_output[:, :-1, :])
             superposed_out = relay_out + encoder_output[:, 1:, :]
 
             with torch.no_grad():
@@ -125,14 +120,24 @@
         print_loss(val_losses, "Val")
 
         mean_loss = np.mean(val_losses)
-        if mean_loss < best_loss:
-            create_checkpoint(
-                path=os.path.join(
-                    args.checkpoint_path,
-                    f"receiver-decoder/receiver_decoder_{epoch}.pt",
-                ),
-                model_state_dict=receiver_decoder.state_dict(),
+
+        checkpoint_path = os.path.join(
+            args.checkpoint_path,
+            f"receiver-decoder/receiver_decoder_{epoch}.pt",
+        )
+
+        if mean_loss < best_loss:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=relay_decoder.state_dict(),
                 optimizer_state_dict=optimizer.state_dict(),
                 mean_val_loss=mean_loss,
             )
             best_loss = mean_loss
+        else:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=None,
+                optimizer_state_dict=None,
+                mean_val_loss=mean_loss,
+            )
Index: end_to_end_v2.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\n\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\n\nfrom semantic_communication.data_processing.data_handler import DataHandler\nfrom semantic_communication.models.transceiver import (\n    TxRelayChannelModel,\n    TxRelayRxChannelModel,\n    Transceiver,\n)\nfrom semantic_communication.utils.channel import AWGN, Rayleigh\nfrom semantic_communication.models.semantic_decoder import SemanticDecoder\nfrom semantic_communication.models.semantic_encoder import SemanticEncoder\nfrom semantic_communication.utils.general import (\n    get_device,\n    print_loss,\n    create_checkpoint,\n)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--relay-decoder-path\", type=str)\n    parser.add_argument(\"--receiver-decoder-path\", type=str)\n    parser.add_argument(\"--tx-relay-channel-model-path\", type=str)\n    parser.add_argument(\"--tx-relay-rx-channel-model-path\", type=str)\n    parser.add_argument(\"--checkpoint-path\", default=\"checkpoints\", type=str)\n    parser.add_argument(\"--n-samples\", default=10000, type=int)\n    parser.add_argument(\"--train-size\", default=0.9, type=float)\n    parser.add_argument(\"--val-size\", default=0.2, type=float)\n    parser.add_argument(\"--max-length\", default=30, type=int)\n    parser.add_argument(\"--batch-size\", default=32, type=int)\n    parser.add_argument(\"--n-epochs\", default=10, type=int)\n    parser.add_argument(\"--lr\", default=1e-4, type=float)\n    parser.add_argument(\"--n-blocks\", default=1, type=int)\n    parser.add_argument(\"--n-heads\", default=4, type=int)\n    parser.add_argument(\"--n-embeddings\", default=384, type=int)\n\n    # New args\n    parser.add_argument(\"--channel-block-input-dim\", default=384, type=int)\n    parser.add_argument(\"--channel-block-latent-dim\", default=128, type=int)\n    parser.add_argument(\"--sig-pow\", default=1.0, type=float)\n    parser.add_argument(\"--SNR-min\", default=3, type=int)\n    parser.add_argument(\"--SNR-max\", default=21, type=int)\n    parser.add_argument(\"--SNR-step\", default=3, type=int)\n    parser.add_argument(\"--SNR-window\", default=5, type=int)\n    parser.add_argument(\"--SNR-diff\", default=3, type=int)\n    parser.add_argument(\"--channel-type\", default=\"AWGN\", type=str)\n    args = parser.parse_args()\n\n    device = get_device()\n\n    semantic_encoder = SemanticEncoder(max_length=args.max_length)\n    data_handler = DataHandler(\n        semantic_encoder=semantic_encoder,\n        batch_size=args.batch_size,\n        n_samples=args.n_samples,\n        train_size=args.train_size,\n        val_size=args.val_size\n    )\n    data_handler.load_data()\n\n    # Initializations\n    SNR_dB = np.flip(np.arange(args.SNR_min, args.SNR_max + 1, args.SNR_step))\n\n    if args.channel_type == \"AWGN\":\n        tx_rx_channel = AWGN(SNR_dB[0] - args.SNR_diff, args.sig_pow)\n        tx_relay_channel = AWGN(SNR_dB[0], args.sig_pow)\n        relay_rx_channel = AWGN(SNR_dB[0], args.sig_pow)\n\n    else:\n        tx_rx_channel = Rayleigh(SNR_dB[0] - args.SNR_diff, args.sig_pow)\n        tx_relay_channel = Rayleigh(SNR_dB[0], args.sig_pow)\n        relay_rx_channel = Rayleigh(SNR_dB[0], args.sig_pow)\n\n    relay_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n    ).to(device)\n    relay_checkpoint = torch.load(args.relay_decoder_path)\n    relay_decoder.load_state_dict(relay_checkpoint[\"model_state_dict\"])\n\n    receiver_decoder = SemanticDecoder(\n        vocab_size=data_handler.vocab_size,\n        n_blocks=args.n_blocks,\n        n_heads=args.n_heads,\n        n_embeddings=args.n_embeddings,\n        block_size=args.max_length,\n    ).to(device)\n\n    rx_checkpoint = torch.load(args.receiver_decoder_path)\n    receiver_decoder.load_state_dict(rx_checkpoint[\"model_state_dict\"])\n\n    tx_relay_channel_model = TxRelayChannelModel(nin=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel=tx_relay_channel).to(device)\n    tx_relay_rx_channel_model = TxRelayRxChannelModel(\n        nin=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel_tx_rx=tx_rx_channel, channel_rel_rx=relay_rx_channel\n    ).to(device)\n\n    tx_relay_channel_model_checkpoint = torch.load(\n        args.tx_relay_channel_model_path\n    )\n    tx_relay_channel_model.load_state_dict(\n        tx_relay_channel_model_checkpoint[\"model_state_dict\"]\n    )\n\n    tx_relay_rx_channel_model_checkpoint = torch.load(\n        args.tx_relay_rx_channel_model_path\n    )\n    tx_relay_rx_channel_model.load_state_dict(\n        tx_relay_rx_channel_model_checkpoint[\"model_state_dict\"]\n    )\n\n    transceiver = Transceiver(\n        semantic_encoder,\n        relay_decoder,\n        receiver_decoder,\n        tx_relay_channel_model,\n        tx_relay_rx_channel_model,\n    )\n\n    optimizer = torch.optim.AdamW(transceiver.parameters(), lr=args.lr)\n\n    best_loss = 5\n    cur_win, cur_SNR_index = 0, 0\n\n    for epoch in range(args.n_epochs):\n        train_losses = []\n        transceiver.train()\n        if cur_win >= args.SNR_window:\n            cur_win = 0\n            if not cur_SNR_index >= len(SNR_dB) - 1:\n                cur_SNR_index += 1\n\n            if args.channel_type == \"AWGN\":\n                tx_rx_channel = AWGN(\n                    SNR_dB[cur_SNR_index] - args.SNR_diff, args.sig_pow\n                )\n                tx_relay_channel = AWGN(\n                    SNR_dB[cur_SNR_index], args.sig_pow\n                )\n                relay_rx_channel = AWGN(\n                    SNR_dB[cur_SNR_index], args.sig_pow\n                )\n\n            else:\n                tx_rx_channel = Rayleigh(\n                    SNR_dB[cur_SNR_index] - args.SNR_diff, args.sig_pow\n                )\n                tx_relay_channel = Rayleigh(\n                    SNR_dB[cur_SNR_index], args.sig_pow\n                )\n                relay_rx_channel = Rayleigh(\n                    SNR_dB[cur_SNR_index], args.sig_pow\n                )\n\n            transceiver.tx_relay_channel_enc_dec.channel = tx_relay_channel\n            transceiver.tx_relay_rx_channel_enc_dec.channel_tx_rx = (\n                tx_rx_channel\n            )\n            transceiver.tx_relay_rx_channel_enc_dec.channel_rel_rx = (\n                relay_rx_channel\n            )\n\n        cur_win += 1\n\n        for b in tqdm(data_handler.train_dataloader):\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n            logits, loss = transceiver(xb, attention_mask)\n\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss.item())\n\n        val_losses = []\n        transceiver.eval()\n        for b in data_handler.val_dataloader:\n            xb = b[0].to(device)\n            attention_mask = b[1].to(device)\n\n            with torch.no_grad():\n                logits, loss = transceiver(xb, attention_mask)\n\n            val_losses.append(loss.item())\n\n        print(\"\\n\")\n        print_loss(train_losses, \"Train\")\n        print_loss(val_losses, \"Val\")\n\n        mean_loss = np.mean(val_losses)\n        if mean_loss < best_loss:\n            create_checkpoint(\n                path=os.path.join(\n                    args.checkpoint_path,\n                    f\"end-to-end-transceiver/end_to_end_transceiver_{epoch}.pt\",\n                ),\n                model_state_dict=transceiver.state_dict(),\n                optimizer_state_dict=optimizer.state_dict(),\n                mean_val_loss=mean_loss,\n            )\n            best_loss = mean_loss\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/end_to_end_v2.py b/end_to_end_v2.py
--- a/end_to_end_v2.py	(revision 1c9506dff07f9306ee05d03ab11a86d6e02a646d)
+++ b/end_to_end_v2.py	(date 1698877854967)
@@ -58,7 +58,7 @@
         batch_size=args.batch_size,
         n_samples=args.n_samples,
         train_size=args.train_size,
-        val_size=args.val_size
+        val_size=args.val_size,
     )
     data_handler.load_data()
 
@@ -96,9 +96,16 @@
     rx_checkpoint = torch.load(args.receiver_decoder_path)
     receiver_decoder.load_state_dict(rx_checkpoint["model_state_dict"])
 
-    tx_relay_channel_model = TxRelayChannelModel(nin=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel=tx_relay_channel).to(device)
+    tx_relay_channel_model = TxRelayChannelModel(
+        nin=args.channel_block_input_dim,
+        n_latent=args.channel_block_latent_dim,
+        channel=tx_relay_channel,
+    ).to(device)
     tx_relay_rx_channel_model = TxRelayRxChannelModel(
-        nin=args.channel_block_input_dim, n_latent=args.channel_block_latent_dim, channel_tx_rx=tx_rx_channel, channel_rel_rx=relay_rx_channel
+        nin=args.channel_block_input_dim,
+        n_latent=args.channel_block_latent_dim,
+        channel_tx_rx=tx_rx_channel,
+        channel_rel_rx=relay_rx_channel,
     ).to(device)
 
     tx_relay_channel_model_checkpoint = torch.load(
@@ -140,12 +147,8 @@
                 tx_rx_channel = AWGN(
                     SNR_dB[cur_SNR_index] - args.SNR_diff, args.sig_pow
                 )
-                tx_relay_channel = AWGN(
-                    SNR_dB[cur_SNR_index], args.sig_pow
-                )
-                relay_rx_channel = AWGN(
-                    SNR_dB[cur_SNR_index], args.sig_pow
-                )
+                tx_relay_channel = AWGN(SNR_dB[cur_SNR_index], args.sig_pow)
+                relay_rx_channel = AWGN(SNR_dB[cur_SNR_index], args.sig_pow)
 
             else:
                 tx_rx_channel = Rayleigh(
@@ -194,14 +197,24 @@
         print_loss(val_losses, "Val")
 
         mean_loss = np.mean(val_losses)
-        if mean_loss < best_loss:
-            create_checkpoint(
-                path=os.path.join(
-                    args.checkpoint_path,
-                    f"end-to-end-transceiver/end_to_end_transceiver_{epoch}.pt",
-                ),
-                model_state_dict=transceiver.state_dict(),
+
+        checkpoint_path = os.path.join(
+            args.checkpoint_path,
+            f"end-to-end-transceiver/end_to_end_transceiver_{epoch}.pt",
+        )
+
+        if mean_loss < best_loss:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=relay_decoder.state_dict(),
                 optimizer_state_dict=optimizer.state_dict(),
                 mean_val_loss=mean_loss,
             )
             best_loss = mean_loss
+        else:
+            create_checkpoint(
+                path=checkpoint_path,
+                model_state_dict=None,
+                optimizer_state_dict=None,
+                mean_val_loss=mean_loss,
+            )
